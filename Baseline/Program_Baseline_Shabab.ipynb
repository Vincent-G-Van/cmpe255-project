{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36254f40-9c3a-4004-9131-58d47fa69558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1711eeef-3d2c-4749-a068-2f350e1e2244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup debug for prints troubleshooting\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad17f921-0711-4537-961b-6ff6ed40c017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../C50train\n",
      "['AaronPressman' 'AlanCrosby' 'AlexanderSmith' 'BenjaminKangLim'\n",
      " 'BernardHickey' 'BradDorfman' 'DarrenSchuettler' 'DavidLawder'\n",
      " 'EdnaFernandes' 'EricAuchard' 'FumikoFujisaki' 'GrahamEarnshaw'\n",
      " 'HeatherScoffield' 'JaneMacartney' 'JanLopatka' 'JimGilchrist' 'JoeOrtiz'\n",
      " 'JohnMastrini' 'JonathanBirt' 'JoWinterbottom' 'KarlPenhaul' 'KeithWeir'\n",
      " 'KevinDrawbaugh' 'KevinMorrison' 'KirstinRidley' 'KouroshKarimkhany'\n",
      " 'LydiaZajc' \"LynneO'Donnell\" 'LynnleyBrowning' 'MarcelMichelson'\n",
      " 'MarkBendeich' 'MartinWolk' 'MatthewBunce' 'MichaelConnor' 'MureDickie'\n",
      " 'NickLouth' 'PatriciaCommins' 'PeterHumphrey' 'PierreTran' 'RobinSidel'\n",
      " 'RogerFillion' 'SamuelPerry' 'SarahDavison' 'ScottHillis' 'SimonCowell'\n",
      " 'TanEeLyn' 'TheresePoletti' 'TimFarrand' 'ToddNissen' 'WilliamKazer']\n",
      "(2500,)\n",
      "(2500,)\n",
      "[50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50\n",
      " 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50\n",
      " 50 50]\n",
      "The Internet may be overflowing with new technology but crime in cyberspace is still of the old-fashioned variety.The National Consumers League said Wednesday that the most popular scam on the Internet was the pyramid scheme, in which early investors in a bogus fund are paid off with deposits of later investors.The league, a non-profit consumer advocacy group, tracks web scams through a site it set up on the world wide web in February called Internet Fraud Watch at http://www.fraud.org.The site, which collects reports directly from consumers, has been widely praised by law enforcement agencies.\"Consumers who suspect a scam on the Internet have critical information,\" said Jodie Bernstein, director of the Federal Trade Commission's Bureau of Consumer Protection. Internet Fraud Watch \"has been a major help to the FTC in identifying particular scams in their infancy.\"In May, for example, the commission used Internet reports to shut down a site run by Fortuna Alliance that had taken in over $6 million, promising investors they could earn $5,000 a month from an initial deposit of $250. Instead, Fortuna kept most of the money, the commission charged.Fraud reports from the league's site, which has been visited over 370,000 times, are forwarded to local, state and federal authorities.The second-most-popular Internet scam, the league said, was the sale of bogus Internet services, such as custom designed web sites or Internet access accounts.In third place were crooks who sell computer equipment, such as memory chips or sound boards, over the net and then deliver significantly lower quality goods or nothing at all, the league said.Other top scams involve business opportunities. Con artists may offer shares in a business or franchise using unreasonable predictions or misrepresentations. One popular scheme promised to let consumers get rich while working at home.The League also announced Tuesday that NationsBank had donated $100,000 to become a sponsor of the Fraud Watch site.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Load in C50train located ../C50train/\n",
    "train_dir = '../C50train'\n",
    "# get name of directories, authors (these will be the labels)\n",
    "train_sub = [name for name in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, name))]\n",
    "label_lst = np.copy(train_sub)\n",
    "\n",
    "if debug:\n",
    "    print(train_dir)\n",
    "    print(label_lst)\n",
    "\n",
    "# setup the initial empty variables\n",
    "train = []\n",
    "train_v = []\n",
    "label = []\n",
    "\n",
    "# load the input data from C50train directory and process it\n",
    "\n",
    "# format will be something like this\n",
    "# ===================================\n",
    "# | Label         | Train           |\n",
    "# ===================================\n",
    "# | AaronPressman | 2537newsML.txt  |\n",
    "# ===================================\n",
    "# | AaronPressman | 14014newsML.txt |\n",
    "# ===================================\n",
    "# | ...           | ...             |\n",
    "# ===================================\n",
    "# | AlanCrosby    | 10306newsML.txt |\n",
    "# ===================================\n",
    "# | ...           | ...             |\n",
    "\n",
    "\n",
    "auth_idx = 0\n",
    "\n",
    "# go within the author directory to get list of the file names, this will be the training data\n",
    "for i in train_sub:\n",
    "    sub2_dir  = '../C50train/' + i \n",
    "    train_sub2 = [name for name in os.listdir(sub2_dir) if os.path.isfile(os.path.join(sub2_dir, name))]\n",
    "\n",
    "    #if debug:\n",
    "    #    print(sub2_dir)\n",
    "    #    print(train_sub2)\n",
    "        \n",
    "    # in each author file, save the author as the label and the text as its training data\n",
    "    for j in train_sub2:\n",
    "        sub3  = '../C50train/' + i + '/' + j\n",
    "\n",
    "        with open(sub3, 'r') as file:\n",
    "            data = file.read()\n",
    "            data_no_nw = data.replace('\\n', '').replace('\\r', '')\n",
    "            train.append(data_no_nw)\n",
    "\n",
    "        # append author index as label\n",
    "        label.append(auth_idx)\n",
    "\n",
    "    # increment author index\n",
    "    auth_idx = auth_idx + 1\n",
    "        \n",
    "        #if debug:\n",
    "        #    print(sub3)\n",
    "\n",
    "if debug:\n",
    "    print(np.shape(train))\n",
    "    print(np.shape(label))\n",
    "\n",
    "    # bin count looking at label\n",
    "    unused, idx = np.unique(label, return_counts=True)\n",
    "    #print(unused)\n",
    "    print(idx)\n",
    "\n",
    "    print(train[0])\n",
    "    print(label[0])\n",
    "    #print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e772bdec-4cc2-4d0b-8edf-0f3d5ce2be18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.80      0.67         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       0.75      0.50      0.60         6\n",
      "           3       0.40      0.67      0.50         3\n",
      "           4       0.60      0.75      0.67         4\n",
      "           5       1.00      0.71      0.83         7\n",
      "           6       1.00      0.80      0.89         5\n",
      "           7       0.50      0.50      0.50         2\n",
      "           8       0.56      1.00      0.71         5\n",
      "           9       1.00      0.40      0.57         5\n",
      "          10       0.90      1.00      0.95         9\n",
      "          11       0.88      0.88      0.88         8\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       0.70      1.00      0.82         7\n",
      "          14       1.00      0.60      0.75         5\n",
      "          15       1.00      1.00      1.00         6\n",
      "          16       0.60      0.75      0.67         4\n",
      "          17       0.60      1.00      0.75         3\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       1.00      1.00      1.00         4\n",
      "          20       1.00      1.00      1.00         7\n",
      "          21       1.00      0.33      0.50         6\n",
      "          22       0.75      0.60      0.67         5\n",
      "          23       1.00      0.50      0.67         4\n",
      "          24       0.67      0.67      0.67         6\n",
      "          25       1.00      1.00      1.00         5\n",
      "          26       0.78      1.00      0.88         7\n",
      "          27       1.00      1.00      1.00         4\n",
      "          28       1.00      1.00      1.00         6\n",
      "          29       0.83      1.00      0.91         5\n",
      "          30       0.75      1.00      0.86         3\n",
      "          31       1.00      0.82      0.90        11\n",
      "          32       1.00      1.00      1.00         4\n",
      "          33       1.00      0.86      0.92         7\n",
      "          34       0.00      0.00      0.00         4\n",
      "          35       0.75      0.75      0.75         4\n",
      "          36       0.86      1.00      0.92         6\n",
      "          37       0.20      0.50      0.29         2\n",
      "          38       1.00      0.57      0.73         7\n",
      "          39       1.00      1.00      1.00         3\n",
      "          40       0.80      1.00      0.89         4\n",
      "          41       0.38      1.00      0.55         3\n",
      "          42       1.00      0.67      0.80         3\n",
      "          43       0.00      0.00      0.00         4\n",
      "          44       0.60      0.75      0.67         4\n",
      "          45       1.00      0.33      0.50         6\n",
      "          46       0.75      0.60      0.67         5\n",
      "          47       0.86      1.00      0.92         6\n",
      "          48       0.25      0.50      0.33         2\n",
      "          49       0.60      0.43      0.50         7\n",
      "\n",
      "    accuracy                           0.78       250\n",
      "   macro avg       0.78      0.76      0.74       250\n",
      "weighted avg       0.82      0.78      0.77       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split the test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.1, random_state=1)\n",
    "\n",
    "# vectorize x_train and x_test from text to matrix\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "x_train_vec = vect.fit_transform(X_train)\n",
    "x_test_vec = vect.transform(X_test)\n",
    "\n",
    "# use logistical regression\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train_vec, y_train)\n",
    "\n",
    "# predict and check accuracy\n",
    "pred = model.predict(x_test_vec)\n",
    "rep = classification_report(y_test, pred)\n",
    "\n",
    "if debug:\n",
    "    print(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28313495-93f3-4639-a7c8-6ae25e2fe00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../C50test\n",
      "['AaronPressman' 'AlanCrosby' 'AlexanderSmith' 'BenjaminKangLim'\n",
      " 'BernardHickey' 'BradDorfman' 'DarrenSchuettler' 'DavidLawder'\n",
      " 'EdnaFernandes' 'EricAuchard' 'FumikoFujisaki' 'GrahamEarnshaw'\n",
      " 'HeatherScoffield' 'JaneMacartney' 'JanLopatka' 'JimGilchrist' 'JoeOrtiz'\n",
      " 'JohnMastrini' 'JonathanBirt' 'JoWinterbottom' 'KarlPenhaul' 'KeithWeir'\n",
      " 'KevinDrawbaugh' 'KevinMorrison' 'KirstinRidley' 'KouroshKarimkhany'\n",
      " 'LydiaZajc' \"LynneO'Donnell\" 'LynnleyBrowning' 'MarcelMichelson'\n",
      " 'MarkBendeich' 'MartinWolk' 'MatthewBunce' 'MichaelConnor' 'MureDickie'\n",
      " 'NickLouth' 'PatriciaCommins' 'PeterHumphrey' 'PierreTran' 'RobinSidel'\n",
      " 'RogerFillion' 'SamuelPerry' 'SarahDavison' 'ScottHillis' 'SimonCowell'\n",
      " 'TanEeLyn' 'TheresePoletti' 'TimFarrand' 'ToddNissen' 'WilliamKazer']\n",
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "# Load in C50test located ../C50test/\n",
    "test_dir = '../C50test'\n",
    "# get name of directories, authors (these will be the labels)\n",
    "test_sub = [name for name in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, name))]\n",
    "test_lst = np.copy(train_sub)\n",
    "\n",
    "if debug:\n",
    "    print(test_dir)\n",
    "    print(test_lst)\n",
    "\n",
    "# setup the initial empty variables\n",
    "test       = []\n",
    "test_label = []\n",
    "\n",
    "# load the input data from C50test directory and process it\n",
    "\n",
    "auth_idx = 0\n",
    "\n",
    "# go within the author directory to get list of the file names, this will be the training data\n",
    "for i in train_sub:\n",
    "    sub2_dir  = '../C50test/' + i \n",
    "    test_sub2 = [name for name in os.listdir(sub2_dir) if os.path.isfile(os.path.join(sub2_dir, name))]\n",
    "\n",
    "    #if debug:\n",
    "    #    print(sub2_dir)\n",
    "    #    print(train_sub2)\n",
    "        \n",
    "    # in each author file, save the text as its test data\n",
    "    for j in test_sub2:\n",
    "        sub3  = '../C50test/' + i + '/' + j\n",
    "\n",
    "        with open(sub3, 'r') as file:\n",
    "            data = file.read()\n",
    "            data_no_nw = data.replace('\\n', '').replace('\\r', '')\n",
    "            test.append(data_no_nw)\n",
    "        \n",
    "        test_label.append(auth_idx)\n",
    "\n",
    "    auth_idx = auth_idx + 1\n",
    "\n",
    "if debug:\n",
    "    print(np.shape(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2afa7db-fa43-4daa-9ae4-715cb3768b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0 44  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 41  0  0\n",
      "  5  0  1  1  1  1 17  1 14 17  1 21 17 17  1 14 14  1 14 14  1  1  1 17\n",
      "  1 17 17  1 17 17 17 17 17 17  1  1  1  1 14  1 14  1  1 17 17 17 17  1\n",
      "  1  1  1  1  2 16  2 16 16 16 16 16 16 16  2 16  2 16 16 16 16 16 16 16\n",
      " 16 16  2 16 16 16 16  2 44  2 44  2 16 16  0  2 16  2 16 16 16 16 16 16\n",
      " 16 18  2  2 16  2 13 37  3 49 11 27 11 49  3 13  3  3 43  3 37 43 13 13\n",
      " 13  3 49 13 13  3 37  3  3 49 49 49 43 43 13 13 34 34 34 34 34 34 34 34\n",
      " 34 13 49 34  3 49 43 43  4  4  4  4  4  4  4  4  4 23  4  5  5 23 23 30\n",
      " 23  4 30 23 30 23 23 23  4  4  4  4  4 23  4 23  4  4 23 23 23 23 23  4\n",
      "  4  4  4 23 23 23 23 23 23 30  5  5  5  5  5  5 41  5  5  5  5  9  5  5\n",
      " 39 39  5 22  5  5  5  5 22  5  5  5  5  9  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5 35  5  5 22  5  5 12  6  6  6  6 12  6  6  6 12  6 12\n",
      "  6 12 12 12 12 12 12 12  6 12 12 12 12 12 12 12  6 12 12 12 12  6  6 12\n",
      " 12  6 12 12 12 12 12 12 12 12 12 12 12 12 48  7  7 48 36 36  7  5  5 48\n",
      " 48 48 33 48  7 48 39 48  7 48 41 48 48 48  7 48 48 48 48 48 48 48 48  7\n",
      " 48 48 43 48  7  7  7 48 48 48  5  7  7 48  7  7  8  8 30  8  8  8 39 39\n",
      " 39 39 47 47  8 19 19 19  8  8 48 30  8 18 47 47 48 48  8 19 48 48 48 48\n",
      " 48  8  8  8 18  8  8  8  8  8  8 47 39 39  8  8  8  8 22  9  9  9  9  9\n",
      "  9  9 22  9 46 46  9  9  5 40 46 25 41 41  9  9  9  9  9  9  9  9  9  9\n",
      "  9 41 40 40 40 46  9 35 35 22 35 35 35 35 35 35 35 35 35 41 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11\n",
      " 11 49 11 11 11 15 11 11 11 34 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 13 43 11 11\n",
      " 12 12 12 12 12 12 12 12  6  6 12 12 12 12  6 12 12  6  6  6  6 12  6 12\n",
      " 12  6  6 17 17 17  6 12  6 13  6  6 43 43 43 43 13 43 43 29 17 20  6  6\n",
      " 12  6 11 43  3 43 34 34 43 34 13  3 37 13 49  3 34 11  3 34 43 34  3 43\n",
      "  3 34 34 43 43 34 43 34 34 34 43 13 43 43  3 43 43 43  3 43 43 43 43 43\n",
      " 43 43 43  3 14 14 14 17 14 17 17 17 17 17 17 14  1 17 28 17 28 17 17 17\n",
      " 17 14 17 14 14 28 17 14 17 17 14 14 14 14 28 17 17 17 17 17 17 17 17 17\n",
      " 14 14 14 14 17 14 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16  8 16 16 16 16  2 44 16 16\n",
      " 23 44 44 16 16 16 16 16 16 16 16 16 16 16 16 16  2 16 16  2 16 16 16 16\n",
      " 44 44 44 44 44 16 16 16 16 44 17 17 17 17 17 17 17 17 17 17 17 14 14 17\n",
      " 14 14 14 17 17 17 17  1 17 17 17 14 17 14 17 14 17 28 17 17 17 17 17 17\n",
      " 17 17 17 17 17 17 14 14 17 14 14 14 18 18 18 19 18 18 18 18 18 28 18 18\n",
      " 18 18 18 18 18 18 18 18 18 18 18 18 47 47 18 47 18 44 44 47 47 18 18 18\n",
      "  8 18 18 18 18 47 18 18 18 18  8 18 18 18 19 19 19 19 19 19 19 19 19 19\n",
      " 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19  5 47\n",
      " 19 19 19 19 19 19 19 19 19 19 19 19 19 18 19]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88        50\n",
      "           1       0.93      0.50      0.65        50\n",
      "           2       0.65      0.26      0.37        50\n",
      "           3       0.31      0.20      0.24        50\n",
      "           4       0.66      0.46      0.54        50\n",
      "           5       0.63      0.82      0.71        50\n",
      "           6       0.33      0.28      0.30        50\n",
      "           7       0.58      0.28      0.38        50\n",
      "           8       0.82      0.46      0.59        50\n",
      "           9       0.39      0.44      0.42        50\n",
      "          10       0.93      1.00      0.96        50\n",
      "          11       0.75      0.90      0.82        50\n",
      "          12       0.33      0.38      0.35        50\n",
      "          13       0.12      0.06      0.08        50\n",
      "          14       0.47      0.36      0.41        50\n",
      "          15       0.89      1.00      0.94        50\n",
      "          16       0.47      0.72      0.57        50\n",
      "          17       0.42      0.70      0.53        50\n",
      "          18       0.70      0.76      0.73        50\n",
      "          19       0.87      0.94      0.90        50\n",
      "          20       0.94      0.98      0.96        50\n",
      "          21       0.77      0.80      0.78        50\n",
      "          22       0.59      0.76      0.67        50\n",
      "          23       0.48      0.64      0.55        50\n",
      "          24       0.96      0.50      0.66        50\n",
      "          25       0.81      0.70      0.75        50\n",
      "          26       0.97      0.68      0.80        50\n",
      "          27       0.91      0.80      0.85        50\n",
      "          28       0.85      1.00      0.92        50\n",
      "          29       0.67      0.74      0.70        50\n",
      "          30       0.73      0.66      0.69        50\n",
      "          31       0.83      0.50      0.62        50\n",
      "          32       0.96      0.90      0.93        50\n",
      "          33       0.83      0.86      0.84        50\n",
      "          34       0.27      0.44      0.33        50\n",
      "          35       0.69      0.84      0.76        50\n",
      "          36       0.77      0.60      0.67        50\n",
      "          37       0.43      0.82      0.57        50\n",
      "          38       0.81      0.58      0.67        50\n",
      "          39       0.75      0.78      0.76        50\n",
      "          40       0.88      0.74      0.80        50\n",
      "          41       0.54      0.72      0.62        50\n",
      "          42       0.60      0.48      0.53        50\n",
      "          43       0.23      0.32      0.27        50\n",
      "          44       0.65      0.88      0.75        50\n",
      "          45       0.52      0.26      0.35        50\n",
      "          46       0.80      0.80      0.80        50\n",
      "          47       0.67      0.76      0.71        50\n",
      "          48       0.38      0.52      0.44        50\n",
      "          49       0.34      0.24      0.28        50\n",
      "\n",
      "    accuracy                           0.63      2500\n",
      "   macro avg       0.65      0.63      0.63      2500\n",
      "weighted avg       0.65      0.63      0.63      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_test_vec = vect.transform(test)\n",
    "\n",
    "new_pred = model.predict(new_test_vec)\n",
    "\n",
    "rep = classification_report(test_label, new_pred)\n",
    "\n",
    "if debug:\n",
    "    print(new_pred[0:999])\n",
    "    print(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af96543-76e9-42f4-baa3-d975d60352b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
