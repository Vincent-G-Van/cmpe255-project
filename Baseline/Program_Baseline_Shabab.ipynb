{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devil-of-silicon-valley/cmpe255-project/blob/shabab/Baseline/Program_Baseline_Shabab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group 5:  Reuter_50_50 Data Set (https://archive.ics.uci.edu/ml/datasets/Reuter_50_50Links to an external site.)\n",
        "\n",
        "Identify the author of an article based on attributes describing their writing style"
      ],
      "metadata": {
        "id": "vdxhYLLfQRyW"
      },
      "id": "vdxhYLLfQRyW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GOAL: Identify the author of an article based on attributes describing their writing style**"
      ],
      "metadata": {
        "id": "RZb9dovWQV2E"
      },
      "id": "RZb9dovWQV2E"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajIcfH9VPPlD",
        "outputId": "592b2688-de49-4600-f7ce-aab855601d3b"
      },
      "id": "ajIcfH9VPPlD",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "36254f40-9c3a-4004-9131-58d47fa69558",
      "metadata": {
        "id": "36254f40-9c3a-4004-9131-58d47fa69558"
      },
      "outputs": [],
      "source": [
        "# import libaries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import f1_score\n",
        "from glob import glob\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1711eeef-3d2c-4749-a068-2f350e1e2244",
      "metadata": {
        "id": "1711eeef-3d2c-4749-a068-2f350e1e2244"
      },
      "outputs": [],
      "source": [
        "# setup debug for prints troubleshooting\n",
        "debug = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_json(json_file):\n",
        "  with open(json_file) as f:\n",
        "    data = json.load(f)\n",
        "  return data\n",
        "\n",
        "def write_json(json_file, data):\n",
        "  with open(json_file, \"w\") as outfile:\n",
        "    json.dump(data, outfile)"
      ],
      "metadata": {
        "id": "1CPu0algb1xv"
      },
      "id": "1CPu0algb1xv",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Dataset Construction\n",
        "\n",
        "The following code was used to parse the raw dataset to create training and testing JSONs that will be used for classification models.\n",
        "\n",
        "These resulting JSONs will also make it faster to load the dataset."
      ],
      "metadata": {
        "id": "h-vwDuPmBk59"
      },
      "id": "h-vwDuPmBk59"
    },
    {
      "cell_type": "code",
      "source": [
        "# get the train and set directories\n",
        "train_dir = '/content/drive/MyDrive/Assignments/03: FA24: CMPE-255 Sec 33 - Data Mining/Project/C50train'\n",
        "test_dir = '/content/drive/MyDrive/Assignments/03: FA24: CMPE-255 Sec 33 - Data Mining/Project/C50test'"
      ],
      "metadata": {
        "id": "9KgZ1uCmP0eH"
      },
      "id": "9KgZ1uCmP0eH",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function to load the data from the directories\n",
        "def parse_raw_data(dir, json_save_dir, debug=False):\n",
        "\n",
        "  print(f\"Creating JSON from data in {dir}\")\n",
        "\n",
        "  # initialize empty dictionary to fill with author information\n",
        "  data_dict = {}\n",
        "\n",
        "  # get the list of author directories\n",
        "  author_dirs = sorted(glob(f\"{dir}/*\"))\n",
        "  print(f\"Found {len(author_dirs)} authors...\")\n",
        "\n",
        "  # now parse the directories for the author names and their associated texts\n",
        "  for author_dir in author_dirs:\n",
        "\n",
        "    # get the author name from the directory\n",
        "    author_name = author_dir.split('/')[-1]\n",
        "\n",
        "    if debug: print(f\"Loading files for {author_name}\")\n",
        "\n",
        "    total_files = len(glob(f\"{author_dir}/*.txt\"))\n",
        "    if debug: print(f\"Found {total_files} files for {author_name}\")\n",
        "\n",
        "    author_file_entry = {}\n",
        "    for file_entry in sorted(glob(f\"{author_dir}/*.txt\")):\n",
        "      # get te filename (ex: 2537newsML.txt)\n",
        "      author_filename = file_entry.split('/')[-1]\n",
        "      # Read the file and remove any new lines or raw strings\n",
        "      author_file = open(file_entry, \"r\").read().replace('\\n', '').replace('\\r', '')\n",
        "      # create the dictionary accordingly\n",
        "      author_file_entry[author_filename] = author_file\n",
        "      # example of an entry \"Author1\" : {\"1234text.txt\" : \"Text for this entry\"}\n",
        "\n",
        "    if debug: print(f\"Adding {author_name} to data dictionary\")\n",
        "\n",
        "    # add the dictionary entry for the current author and their files\n",
        "    data_dict[author_name] = author_file_entry\n",
        "\n",
        "  write_json(json_save_dir, data_dict)\n",
        "\n",
        "  return data_dict"
      ],
      "metadata": {
        "id": "q1lrt-VQKeyB"
      },
      "id": "q1lrt-VQKeyB",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_json_save_dir = '/content/drive/MyDrive/Assignments/03: FA24: CMPE-255 Sec 33 - Data Mining/Project/C50train.json'\n",
        "test_json_save_dir = '/content/drive/MyDrive/Assignments/03: FA24: CMPE-255 Sec 33 - Data Mining/Project/C50test.json'\n",
        "train_json = parse_raw_data(dir=train_dir, json_save_dir=train_json_save_dir)\n",
        "test_json = parse_raw_data(dir=test_dir, json_save_dir=test_json_save_dir)"
      ],
      "metadata": {
        "id": "j22033DaQeHL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c473e073-0d0f-44ca-c791-9cfac1e17850"
      },
      "id": "j22033DaQeHL",
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating JSON from data in /content/drive/MyDrive/Assignments/03: FA24: CMPE-255 Sec 33 - Data Mining/Project/C50train\n",
            "Found 50 authors...\n",
            "Creating JSON from data in /content/drive/MyDrive/Assignments/03: FA24: CMPE-255 Sec 33 - Data Mining/Project/C50test\n",
            "Found 50 authors...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the JSON to make a Dataframe"
      ],
      "metadata": {
        "id": "r-VUaECJCG7y"
      },
      "id": "r-VUaECJCG7y"
    },
    {
      "cell_type": "code",
      "source": [
        "# read the jsons\n",
        "train_json_save_dir = '/content/drive/MyDrive/Assignments/03: FA24: CMPE-255 Sec 33 - Data Mining/Project/C50train.json'\n",
        "test_json_save_dir = '/content/drive/MyDrive/Assignments/03: FA24: CMPE-255 Sec 33 - Data Mining/Project/C50test.json'\n",
        "train_json = load_json(train_json_save_dir)\n",
        "test_json = load_json(test_json_save_dir)"
      ],
      "metadata": {
        "id": "Dv_yjLM_Ozf4"
      },
      "id": "Dv_yjLM_Ozf4",
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try making a dataframe from the JSON we just loaded"
      ],
      "metadata": {
        "id": "VVqHcG-wSdPu"
      },
      "id": "VVqHcG-wSdPu"
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_df = pd.DataFrame(train_json, index=None).T\n",
        "test_data_df = pd.DataFrame(test_json, index=None).T"
      ],
      "metadata": {
        "id": "IwBjahpzSgEb"
      },
      "id": "IwBjahpzSgEb",
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "QGIPFDVVSlnp",
        "outputId": "70ae2b1a-fb50-454b-c249-722fcc0f03d7"
      },
      "id": "QGIPFDVVSlnp",
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  106247newsML.txt  \\\n",
              "AaronPressman    The Internet may be overflowing with new techn...   \n",
              "AlanCrosby                                                     NaN   \n",
              "AlexanderSmith                                                 NaN   \n",
              "BenjaminKangLim                                                NaN   \n",
              "BernardHickey                                                  NaN   \n",
              "\n",
              "                                                  120600newsML.txt  \\\n",
              "AaronPressman    The U.S. Postal Service announced Wednesday a ...   \n",
              "AlanCrosby                                                     NaN   \n",
              "AlexanderSmith                                                 NaN   \n",
              "BenjaminKangLim                                                NaN   \n",
              "BernardHickey                                                  NaN   \n",
              "\n",
              "                                                  120683newsML.txt  \\\n",
              "AaronPressman    Elementary school students with access to the ...   \n",
              "AlanCrosby                                                     NaN   \n",
              "AlexanderSmith                                                 NaN   \n",
              "BenjaminKangLim                                                NaN   \n",
              "BernardHickey                                                  NaN   \n",
              "\n",
              "                                                  136958newsML.txt  \\\n",
              "AaronPressman    An influential Internet organisation has backe...   \n",
              "AlanCrosby                                                     NaN   \n",
              "AlexanderSmith                                                 NaN   \n",
              "BenjaminKangLim                                                NaN   \n",
              "BernardHickey                                                  NaN   \n",
              "\n",
              "                                                  137498newsML.txt  \\\n",
              "AaronPressman    An influential Internet organisation has backe...   \n",
              "AlanCrosby                                                     NaN   \n",
              "AlexanderSmith                                                 NaN   \n",
              "BenjaminKangLim                                                NaN   \n",
              "BernardHickey                                                  NaN   \n",
              "\n",
              "                                                   14014newsML.txt  \\\n",
              "AaronPressman    A group of leading trademark specialists plans...   \n",
              "AlanCrosby                                                     NaN   \n",
              "AlexanderSmith                                                 NaN   \n",
              "BenjaminKangLim                                                NaN   \n",
              "BernardHickey                                                  NaN   \n",
              "\n",
              "                                                  156814newsML.txt  \\\n",
              "AaronPressman    When a company in California sells a book to a...   \n",
              "AlanCrosby                                                     NaN   \n",
              "AlexanderSmith                                                 NaN   \n",
              "BenjaminKangLim                                                NaN   \n",
              "BernardHickey                                                  NaN   \n",
              "\n",
              "                                                  182596newsML.txt  \\\n",
              "AaronPressman    U.S. laws governing the trillion dollar future...   \n",
              "AlanCrosby                                                     NaN   \n",
              "AlexanderSmith                                                 NaN   \n",
              "BenjaminKangLim                                                NaN   \n",
              "BernardHickey                                                  NaN   \n",
              "\n",
              "                                                  186392newsML.txt  \\\n",
              "AaronPressman    Supreme Court justices Wednesday sharply quest...   \n",
              "AlanCrosby                                                     NaN   \n",
              "AlexanderSmith                                                 NaN   \n",
              "BenjaminKangLim                                                NaN   \n",
              "BernardHickey                                                  NaN   \n",
              "\n",
              "                                                  193495newsML.txt  ...  \\\n",
              "AaronPressman    The Internet continued to grow in leaps and bo...  ...   \n",
              "AlanCrosby                                                     NaN  ...   \n",
              "AlexanderSmith                                                 NaN  ...   \n",
              "BenjaminKangLim                                                NaN  ...   \n",
              "BernardHickey                                                  NaN  ...   \n",
              "\n",
              "                258689newsML.txt 264132newsML.txt 268647newsML.txt  \\\n",
              "AaronPressman                NaN              NaN              NaN   \n",
              "AlanCrosby                   NaN              NaN              NaN   \n",
              "AlexanderSmith               NaN              NaN              NaN   \n",
              "BenjaminKangLim              NaN              NaN              NaN   \n",
              "BernardHickey                NaN              NaN              NaN   \n",
              "\n",
              "                278687newsML.txt 281216newsML.txt 28223newsML.txt  \\\n",
              "AaronPressman                NaN              NaN             NaN   \n",
              "AlanCrosby                   NaN              NaN             NaN   \n",
              "AlexanderSmith               NaN              NaN             NaN   \n",
              "BenjaminKangLim              NaN              NaN             NaN   \n",
              "BernardHickey                NaN              NaN             NaN   \n",
              "\n",
              "                282935newsML.txt 287736newsML.txt 289747newsML.txt  \\\n",
              "AaronPressman                NaN              NaN              NaN   \n",
              "AlanCrosby                   NaN              NaN              NaN   \n",
              "AlexanderSmith               NaN              NaN              NaN   \n",
              "BenjaminKangLim              NaN              NaN              NaN   \n",
              "BernardHickey                NaN              NaN              NaN   \n",
              "\n",
              "                304402newsML.txt  \n",
              "AaronPressman                NaN  \n",
              "AlanCrosby                   NaN  \n",
              "AlexanderSmith               NaN  \n",
              "BenjaminKangLim              NaN  \n",
              "BernardHickey                NaN  \n",
              "\n",
              "[5 rows x 2500 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67ff01d3-f6eb-4ba6-b468-e8454450be84\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>106247newsML.txt</th>\n",
              "      <th>120600newsML.txt</th>\n",
              "      <th>120683newsML.txt</th>\n",
              "      <th>136958newsML.txt</th>\n",
              "      <th>137498newsML.txt</th>\n",
              "      <th>14014newsML.txt</th>\n",
              "      <th>156814newsML.txt</th>\n",
              "      <th>182596newsML.txt</th>\n",
              "      <th>186392newsML.txt</th>\n",
              "      <th>193495newsML.txt</th>\n",
              "      <th>...</th>\n",
              "      <th>258689newsML.txt</th>\n",
              "      <th>264132newsML.txt</th>\n",
              "      <th>268647newsML.txt</th>\n",
              "      <th>278687newsML.txt</th>\n",
              "      <th>281216newsML.txt</th>\n",
              "      <th>28223newsML.txt</th>\n",
              "      <th>282935newsML.txt</th>\n",
              "      <th>287736newsML.txt</th>\n",
              "      <th>289747newsML.txt</th>\n",
              "      <th>304402newsML.txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AaronPressman</th>\n",
              "      <td>The Internet may be overflowing with new techn...</td>\n",
              "      <td>The U.S. Postal Service announced Wednesday a ...</td>\n",
              "      <td>Elementary school students with access to the ...</td>\n",
              "      <td>An influential Internet organisation has backe...</td>\n",
              "      <td>An influential Internet organisation has backe...</td>\n",
              "      <td>A group of leading trademark specialists plans...</td>\n",
              "      <td>When a company in California sells a book to a...</td>\n",
              "      <td>U.S. laws governing the trillion dollar future...</td>\n",
              "      <td>Supreme Court justices Wednesday sharply quest...</td>\n",
              "      <td>The Internet continued to grow in leaps and bo...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AlanCrosby</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AlexanderSmith</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BenjaminKangLim</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BernardHickey</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 2500 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67ff01d3-f6eb-4ba6-b468-e8454450be84')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-67ff01d3-f6eb-4ba6-b468-e8454450be84 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-67ff01d3-f6eb-4ba6-b468-e8454450be84');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-24fc76a0-0187-483a-ad32-8ab41cd65df9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24fc76a0-0187-483a-ad32-8ab41cd65df9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-24fc76a0-0187-483a-ad32-8ab41cd65df9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data_df"
            }
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This isnt't very useful because of the NaNs.\n",
        "\n",
        "Refactor the JSON so it's a cleaner more usable format"
      ],
      "metadata": {
        "id": "NwACWcxfSpkM"
      },
      "id": "NwACWcxfSpkM"
    },
    {
      "cell_type": "code",
      "source": [
        "# this function will refactor the data dictionary to a format\n",
        "# that is more friendly for dataframes\n",
        "def refactor_data(data_dict):\n",
        "\n",
        "  # create the dictionary that will be converted to a dataframe\n",
        "  refactored_data_dict = {}\n",
        "\n",
        "  # init list of unique authors\n",
        "  authors = []\n",
        "\n",
        "  # init raw labels (authors) and data (text)\n",
        "  # that will be used for actual training\n",
        "  labels = []\n",
        "  data = []\n",
        "\n",
        "  # parse the dictionary to get the files for each author\n",
        "  for author_entry, file_entry in data_dict.items():\n",
        "\n",
        "    # init the text list for each author\n",
        "    text_list = []\n",
        "\n",
        "    # add the current author to the list of total authors\n",
        "    authors.append(author_entry)\n",
        "\n",
        "    # parse the text list to add to the relevant lists\n",
        "    for file_name, file_text in file_entry.items():\n",
        "      labels.append(author_entry)\n",
        "      data.append(file_text)\n",
        "\n",
        "    refactored_data_dict[author_entry] = data\n",
        "\n",
        "  data_df = pd.DataFrame(refactored_data_dict, index=None).T\n",
        "\n",
        "  return data_df, authors, labels, data"
      ],
      "metadata": {
        "id": "glTU7qtaRlFA"
      },
      "id": "glTU7qtaRlFA",
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_df, train_authors, train_labels, train_data = refactor_data(train_json)\n",
        "test_data_df, test_authors, test_labels, test_data = refactor_data(test_json)"
      ],
      "metadata": {
        "id": "ddMrvZ4bP5Sw"
      },
      "id": "ddMrvZ4bP5Sw",
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_df.head()"
      ],
      "metadata": {
        "id": "Uz4K46neb0K1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "outputId": "7db8380b-8e95-42ed-b582-55391de72f07"
      },
      "id": "Uz4K46neb0K1",
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                              0     \\\n",
              "AaronPressman    The Internet may be overflowing with new techn...   \n",
              "AlanCrosby       The Internet may be overflowing with new techn...   \n",
              "AlexanderSmith   The Internet may be overflowing with new techn...   \n",
              "BenjaminKangLim  The Internet may be overflowing with new techn...   \n",
              "BernardHickey    The Internet may be overflowing with new techn...   \n",
              "\n",
              "                                                              1     \\\n",
              "AaronPressman    The U.S. Postal Service announced Wednesday a ...   \n",
              "AlanCrosby       The U.S. Postal Service announced Wednesday a ...   \n",
              "AlexanderSmith   The U.S. Postal Service announced Wednesday a ...   \n",
              "BenjaminKangLim  The U.S. Postal Service announced Wednesday a ...   \n",
              "BernardHickey    The U.S. Postal Service announced Wednesday a ...   \n",
              "\n",
              "                                                              2     \\\n",
              "AaronPressman    Elementary school students with access to the ...   \n",
              "AlanCrosby       Elementary school students with access to the ...   \n",
              "AlexanderSmith   Elementary school students with access to the ...   \n",
              "BenjaminKangLim  Elementary school students with access to the ...   \n",
              "BernardHickey    Elementary school students with access to the ...   \n",
              "\n",
              "                                                              3     \\\n",
              "AaronPressman    An influential Internet organisation has backe...   \n",
              "AlanCrosby       An influential Internet organisation has backe...   \n",
              "AlexanderSmith   An influential Internet organisation has backe...   \n",
              "BenjaminKangLim  An influential Internet organisation has backe...   \n",
              "BernardHickey    An influential Internet organisation has backe...   \n",
              "\n",
              "                                                              4     \\\n",
              "AaronPressman    An influential Internet organisation has backe...   \n",
              "AlanCrosby       An influential Internet organisation has backe...   \n",
              "AlexanderSmith   An influential Internet organisation has backe...   \n",
              "BenjaminKangLim  An influential Internet organisation has backe...   \n",
              "BernardHickey    An influential Internet organisation has backe...   \n",
              "\n",
              "                                                              5     \\\n",
              "AaronPressman    A group of leading trademark specialists plans...   \n",
              "AlanCrosby       A group of leading trademark specialists plans...   \n",
              "AlexanderSmith   A group of leading trademark specialists plans...   \n",
              "BenjaminKangLim  A group of leading trademark specialists plans...   \n",
              "BernardHickey    A group of leading trademark specialists plans...   \n",
              "\n",
              "                                                              6     \\\n",
              "AaronPressman    When a company in California sells a book to a...   \n",
              "AlanCrosby       When a company in California sells a book to a...   \n",
              "AlexanderSmith   When a company in California sells a book to a...   \n",
              "BenjaminKangLim  When a company in California sells a book to a...   \n",
              "BernardHickey    When a company in California sells a book to a...   \n",
              "\n",
              "                                                              7     \\\n",
              "AaronPressman    U.S. laws governing the trillion dollar future...   \n",
              "AlanCrosby       U.S. laws governing the trillion dollar future...   \n",
              "AlexanderSmith   U.S. laws governing the trillion dollar future...   \n",
              "BenjaminKangLim  U.S. laws governing the trillion dollar future...   \n",
              "BernardHickey    U.S. laws governing the trillion dollar future...   \n",
              "\n",
              "                                                              8     \\\n",
              "AaronPressman    Supreme Court justices Wednesday sharply quest...   \n",
              "AlanCrosby       Supreme Court justices Wednesday sharply quest...   \n",
              "AlexanderSmith   Supreme Court justices Wednesday sharply quest...   \n",
              "BenjaminKangLim  Supreme Court justices Wednesday sharply quest...   \n",
              "BernardHickey    Supreme Court justices Wednesday sharply quest...   \n",
              "\n",
              "                                                              9     ...  \\\n",
              "AaronPressman    The Internet continued to grow in leaps and bo...  ...   \n",
              "AlanCrosby       The Internet continued to grow in leaps and bo...  ...   \n",
              "AlexanderSmith   The Internet continued to grow in leaps and bo...  ...   \n",
              "BenjaminKangLim  The Internet continued to grow in leaps and bo...  ...   \n",
              "BernardHickey    The Internet continued to grow in leaps and bo...  ...   \n",
              "\n",
              "                                                              2490  \\\n",
              "AaronPressman    China has taken its cue from U.S. Federal Rese...   \n",
              "AlanCrosby       China has taken its cue from U.S. Federal Rese...   \n",
              "AlexanderSmith   China has taken its cue from U.S. Federal Rese...   \n",
              "BenjaminKangLim  China has taken its cue from U.S. Federal Rese...   \n",
              "BernardHickey    China has taken its cue from U.S. Federal Rese...   \n",
              "\n",
              "                                                              2491  \\\n",
              "AaronPressman    The Stone Group, a Chinese high technology com...   \n",
              "AlanCrosby       The Stone Group, a Chinese high technology com...   \n",
              "AlexanderSmith   The Stone Group, a Chinese high technology com...   \n",
              "BenjaminKangLim  The Stone Group, a Chinese high technology com...   \n",
              "BernardHickey    The Stone Group, a Chinese high technology com...   \n",
              "\n",
              "                                                              2492  \\\n",
              "AaronPressman    China said on Thursday it strongly opposed a v...   \n",
              "AlanCrosby       China said on Thursday it strongly opposed a v...   \n",
              "AlexanderSmith   China said on Thursday it strongly opposed a v...   \n",
              "BenjaminKangLim  China said on Thursday it strongly opposed a v...   \n",
              "BernardHickey    China said on Thursday it strongly opposed a v...   \n",
              "\n",
              "                                                              2493  \\\n",
              "AaronPressman    A top Chinese defence official has stepped dow...   \n",
              "AlanCrosby       A top Chinese defence official has stepped dow...   \n",
              "AlexanderSmith   A top Chinese defence official has stepped dow...   \n",
              "BenjaminKangLim  A top Chinese defence official has stepped dow...   \n",
              "BernardHickey    A top Chinese defence official has stepped dow...   \n",
              "\n",
              "                                                              2494  \\\n",
              "AaronPressman    China warned on Monday against reinforcing mil...   \n",
              "AlanCrosby       China warned on Monday against reinforcing mil...   \n",
              "AlexanderSmith   China warned on Monday against reinforcing mil...   \n",
              "BenjaminKangLim  China warned on Monday against reinforcing mil...   \n",
              "BernardHickey    China warned on Monday against reinforcing mil...   \n",
              "\n",
              "                                                              2495  \\\n",
              "AaronPressman    China's central bank chief has said that infla...   \n",
              "AlanCrosby       China's central bank chief has said that infla...   \n",
              "AlexanderSmith   China's central bank chief has said that infla...   \n",
              "BenjaminKangLim  China's central bank chief has said that infla...   \n",
              "BernardHickey    China's central bank chief has said that infla...   \n",
              "\n",
              "                                                              2496  \\\n",
              "AaronPressman    China ushered in 1997, a year it has hailed as...   \n",
              "AlanCrosby       China ushered in 1997, a year it has hailed as...   \n",
              "AlexanderSmith   China ushered in 1997, a year it has hailed as...   \n",
              "BenjaminKangLim  China ushered in 1997, a year it has hailed as...   \n",
              "BernardHickey    China ushered in 1997, a year it has hailed as...   \n",
              "\n",
              "                                                              2497  \\\n",
              "AaronPressman    China issued tough new rules on the handling o...   \n",
              "AlanCrosby       China issued tough new rules on the handling o...   \n",
              "AlexanderSmith   China issued tough new rules on the handling o...   \n",
              "BenjaminKangLim  China issued tough new rules on the handling o...   \n",
              "BernardHickey    China issued tough new rules on the handling o...   \n",
              "\n",
              "                                                              2498  \\\n",
              "AaronPressman    China will avoid bold moves in tackling its ai...   \n",
              "AlanCrosby       China will avoid bold moves in tackling its ai...   \n",
              "AlexanderSmith   China will avoid bold moves in tackling its ai...   \n",
              "BenjaminKangLim  China will avoid bold moves in tackling its ai...   \n",
              "BernardHickey    China will avoid bold moves in tackling its ai...   \n",
              "\n",
              "                                                              2499  \n",
              "AaronPressman    Communist Party chief Jiang Zemin has put his ...  \n",
              "AlanCrosby       Communist Party chief Jiang Zemin has put his ...  \n",
              "AlexanderSmith   Communist Party chief Jiang Zemin has put his ...  \n",
              "BenjaminKangLim  Communist Party chief Jiang Zemin has put his ...  \n",
              "BernardHickey    Communist Party chief Jiang Zemin has put his ...  \n",
              "\n",
              "[5 rows x 2500 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfe7e88a-908a-4138-a7a0-bb500a84a235\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>2490</th>\n",
              "      <th>2491</th>\n",
              "      <th>2492</th>\n",
              "      <th>2493</th>\n",
              "      <th>2494</th>\n",
              "      <th>2495</th>\n",
              "      <th>2496</th>\n",
              "      <th>2497</th>\n",
              "      <th>2498</th>\n",
              "      <th>2499</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AaronPressman</th>\n",
              "      <td>The Internet may be overflowing with new techn...</td>\n",
              "      <td>The U.S. Postal Service announced Wednesday a ...</td>\n",
              "      <td>Elementary school students with access to the ...</td>\n",
              "      <td>An influential Internet organisation has backe...</td>\n",
              "      <td>An influential Internet organisation has backe...</td>\n",
              "      <td>A group of leading trademark specialists plans...</td>\n",
              "      <td>When a company in California sells a book to a...</td>\n",
              "      <td>U.S. laws governing the trillion dollar future...</td>\n",
              "      <td>Supreme Court justices Wednesday sharply quest...</td>\n",
              "      <td>The Internet continued to grow in leaps and bo...</td>\n",
              "      <td>...</td>\n",
              "      <td>China has taken its cue from U.S. Federal Rese...</td>\n",
              "      <td>The Stone Group, a Chinese high technology com...</td>\n",
              "      <td>China said on Thursday it strongly opposed a v...</td>\n",
              "      <td>A top Chinese defence official has stepped dow...</td>\n",
              "      <td>China warned on Monday against reinforcing mil...</td>\n",
              "      <td>China's central bank chief has said that infla...</td>\n",
              "      <td>China ushered in 1997, a year it has hailed as...</td>\n",
              "      <td>China issued tough new rules on the handling o...</td>\n",
              "      <td>China will avoid bold moves in tackling its ai...</td>\n",
              "      <td>Communist Party chief Jiang Zemin has put his ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AlanCrosby</th>\n",
              "      <td>The Internet may be overflowing with new techn...</td>\n",
              "      <td>The U.S. Postal Service announced Wednesday a ...</td>\n",
              "      <td>Elementary school students with access to the ...</td>\n",
              "      <td>An influential Internet organisation has backe...</td>\n",
              "      <td>An influential Internet organisation has backe...</td>\n",
              "      <td>A group of leading trademark specialists plans...</td>\n",
              "      <td>When a company in California sells a book to a...</td>\n",
              "      <td>U.S. laws governing the trillion dollar future...</td>\n",
              "      <td>Supreme Court justices Wednesday sharply quest...</td>\n",
              "      <td>The Internet continued to grow in leaps and bo...</td>\n",
              "      <td>...</td>\n",
              "      <td>China has taken its cue from U.S. Federal Rese...</td>\n",
              "      <td>The Stone Group, a Chinese high technology com...</td>\n",
              "      <td>China said on Thursday it strongly opposed a v...</td>\n",
              "      <td>A top Chinese defence official has stepped dow...</td>\n",
              "      <td>China warned on Monday against reinforcing mil...</td>\n",
              "      <td>China's central bank chief has said that infla...</td>\n",
              "      <td>China ushered in 1997, a year it has hailed as...</td>\n",
              "      <td>China issued tough new rules on the handling o...</td>\n",
              "      <td>China will avoid bold moves in tackling its ai...</td>\n",
              "      <td>Communist Party chief Jiang Zemin has put his ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AlexanderSmith</th>\n",
              "      <td>The Internet may be overflowing with new techn...</td>\n",
              "      <td>The U.S. Postal Service announced Wednesday a ...</td>\n",
              "      <td>Elementary school students with access to the ...</td>\n",
              "      <td>An influential Internet organisation has backe...</td>\n",
              "      <td>An influential Internet organisation has backe...</td>\n",
              "      <td>A group of leading trademark specialists plans...</td>\n",
              "      <td>When a company in California sells a book to a...</td>\n",
              "      <td>U.S. laws governing the trillion dollar future...</td>\n",
              "      <td>Supreme Court justices Wednesday sharply quest...</td>\n",
              "      <td>The Internet continued to grow in leaps and bo...</td>\n",
              "      <td>...</td>\n",
              "      <td>China has taken its cue from U.S. Federal Rese...</td>\n",
              "      <td>The Stone Group, a Chinese high technology com...</td>\n",
              "      <td>China said on Thursday it strongly opposed a v...</td>\n",
              "      <td>A top Chinese defence official has stepped dow...</td>\n",
              "      <td>China warned on Monday against reinforcing mil...</td>\n",
              "      <td>China's central bank chief has said that infla...</td>\n",
              "      <td>China ushered in 1997, a year it has hailed as...</td>\n",
              "      <td>China issued tough new rules on the handling o...</td>\n",
              "      <td>China will avoid bold moves in tackling its ai...</td>\n",
              "      <td>Communist Party chief Jiang Zemin has put his ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BenjaminKangLim</th>\n",
              "      <td>The Internet may be overflowing with new techn...</td>\n",
              "      <td>The U.S. Postal Service announced Wednesday a ...</td>\n",
              "      <td>Elementary school students with access to the ...</td>\n",
              "      <td>An influential Internet organisation has backe...</td>\n",
              "      <td>An influential Internet organisation has backe...</td>\n",
              "      <td>A group of leading trademark specialists plans...</td>\n",
              "      <td>When a company in California sells a book to a...</td>\n",
              "      <td>U.S. laws governing the trillion dollar future...</td>\n",
              "      <td>Supreme Court justices Wednesday sharply quest...</td>\n",
              "      <td>The Internet continued to grow in leaps and bo...</td>\n",
              "      <td>...</td>\n",
              "      <td>China has taken its cue from U.S. Federal Rese...</td>\n",
              "      <td>The Stone Group, a Chinese high technology com...</td>\n",
              "      <td>China said on Thursday it strongly opposed a v...</td>\n",
              "      <td>A top Chinese defence official has stepped dow...</td>\n",
              "      <td>China warned on Monday against reinforcing mil...</td>\n",
              "      <td>China's central bank chief has said that infla...</td>\n",
              "      <td>China ushered in 1997, a year it has hailed as...</td>\n",
              "      <td>China issued tough new rules on the handling o...</td>\n",
              "      <td>China will avoid bold moves in tackling its ai...</td>\n",
              "      <td>Communist Party chief Jiang Zemin has put his ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BernardHickey</th>\n",
              "      <td>The Internet may be overflowing with new techn...</td>\n",
              "      <td>The U.S. Postal Service announced Wednesday a ...</td>\n",
              "      <td>Elementary school students with access to the ...</td>\n",
              "      <td>An influential Internet organisation has backe...</td>\n",
              "      <td>An influential Internet organisation has backe...</td>\n",
              "      <td>A group of leading trademark specialists plans...</td>\n",
              "      <td>When a company in California sells a book to a...</td>\n",
              "      <td>U.S. laws governing the trillion dollar future...</td>\n",
              "      <td>Supreme Court justices Wednesday sharply quest...</td>\n",
              "      <td>The Internet continued to grow in leaps and bo...</td>\n",
              "      <td>...</td>\n",
              "      <td>China has taken its cue from U.S. Federal Rese...</td>\n",
              "      <td>The Stone Group, a Chinese high technology com...</td>\n",
              "      <td>China said on Thursday it strongly opposed a v...</td>\n",
              "      <td>A top Chinese defence official has stepped dow...</td>\n",
              "      <td>China warned on Monday against reinforcing mil...</td>\n",
              "      <td>China's central bank chief has said that infla...</td>\n",
              "      <td>China ushered in 1997, a year it has hailed as...</td>\n",
              "      <td>China issued tough new rules on the handling o...</td>\n",
              "      <td>China will avoid bold moves in tackling its ai...</td>\n",
              "      <td>Communist Party chief Jiang Zemin has put his ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 2500 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfe7e88a-908a-4138-a7a0-bb500a84a235')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cfe7e88a-908a-4138-a7a0-bb500a84a235 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cfe7e88a-908a-4138-a7a0-bb500a84a235');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fb5d4533-6b7e-4369-b91c-4b9a989d23ab\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb5d4533-6b7e-4369-b91c-4b9a989d23ab')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fb5d4533-6b7e-4369-b91c-4b9a989d23ab button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data_df"
            }
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This looks a lot better. Maybe this can be used to create a classification model."
      ],
      "metadata": {
        "id": "EiKD6Q11SYKJ"
      },
      "id": "EiKD6Q11SYKJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimenting with Classification Models"
      ],
      "metadata": {
        "id": "yiZZ_CGBtmOd"
      },
      "id": "yiZZ_CGBtmOd"
    },
    {
      "cell_type": "code",
      "source": [
        "# read the jsons\n",
        "train_json_save_dir = '/content/drive/MyDrive/Assignments/03: FA24: CMPE-255 Sec 33 - Data Mining/Project/C50train.json'\n",
        "test_json_save_dir = '/content/drive/MyDrive/Assignments/03: FA24: CMPE-255 Sec 33 - Data Mining/Project/C50test.json'\n",
        "train_json = load_json(train_json_save_dir)\n",
        "test_json = load_json(test_json_save_dir)\n",
        "\n",
        "# this function will refactor the data dictionary to a format\n",
        "# that is more friendly for dataframes\n",
        "def refactor_data(data_dict):\n",
        "  # create the dictionary that will be converted to a dataframe\n",
        "  refactored_data_dict = {}\n",
        "  # init list of unique authors\n",
        "  authors = []\n",
        "  # init raw labels (authors) and data (text)\n",
        "  # that will be used for actual training\n",
        "  labels = []\n",
        "  data = []\n",
        "  # parse the dictionary to get the files for each author\n",
        "  for author_entry, file_entry in data_dict.items():\n",
        "    # init the text list for each author\n",
        "    text_list = []\n",
        "    # add the current author to the list of total authors\n",
        "    authors.append(author_entry)\n",
        "    # parse the text list to add to the relevant lists\n",
        "    for file_name, file_text in file_entry.items():\n",
        "      labels.append(author_entry)\n",
        "      data.append(file_text)\n",
        "    refactored_data_dict[author_entry] = data\n",
        "  data_df = pd.DataFrame(refactored_data_dict, index=None).T\n",
        "  return data_df, authors, labels, data\n",
        "\n",
        "train_data_df, train_authors, train_labels, train_data = refactor_data(train_json)\n",
        "test_data_df, test_authors, test_labels, test_data = refactor_data(test_json)"
      ],
      "metadata": {
        "id": "0GzrpxGYtp-F"
      },
      "id": "0GzrpxGYtp-F",
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_np = np.array(train_labels)\n",
        "train_data_np = np.array(train_data)\n",
        "test_labels_np = np.array(test_labels)\n",
        "test_data_np = np.array(test_data)"
      ],
      "metadata": {
        "id": "SJolhGAsjdv1"
      },
      "id": "SJolhGAsjdv1",
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_data_np, train_labels_np, test_size=0.3, random_state=1)"
      ],
      "metadata": {
        "id": "ZulhBs2-jwKw"
      },
      "id": "ZulhBs2-jwKw",
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize x_train and x_test from text to matrix\n",
        "vect = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# vectorize the training data\n",
        "x_train_vec = vect.fit_transform(X_train)\n",
        "x_test_vec = vect.transform(X_test)\n",
        "\n",
        "# vectorize the actual test set\n",
        "test_data_vec = vect.transform(test_data)"
      ],
      "metadata": {
        "id": "nefMfdCbnxu7"
      },
      "id": "nefMfdCbnxu7",
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier()\n",
        "model.fit(x_train_vec,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "MXBejI8xnFjJ",
        "outputId": "4cfe2032-f7ac-4ca9-ec22-7a294b1b13ab"
      },
      "id": "MXBejI8xnFjJ",
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"â–¸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"â–¾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test_vec)\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "print(f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSAYOgc1n8Rf",
        "outputId": "514ce17c-8c92-45b9-f498-feec0e486c71"
      },
      "id": "GSAYOgc1n8Rf",
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7682470645833175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_data_vec)\n",
        "f1 = f1_score(test_labels_np, predictions, average='weighted')\n",
        "print(f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytUBtbv4oI6t",
        "outputId": "13ce61e1-7236-4f16-ce5b-a77ec34fe832"
      },
      "id": "ytUBtbv4oI6t",
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6119569832688249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rep = classification_report(test_labels_np, predictions)\n",
        "print(rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PzEYg5spkBD",
        "outputId": "f714147c-b80f-490c-f2ad-23b3f69d859d"
      },
      "id": "3PzEYg5spkBD",
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "    AaronPressman       0.70      0.94      0.80        50\n",
            "       AlanCrosby       0.90      0.52      0.66        50\n",
            "   AlexanderSmith       0.62      0.50      0.56        50\n",
            "  BenjaminKangLim       0.28      0.42      0.34        50\n",
            "    BernardHickey       0.50      0.20      0.29        50\n",
            "      BradDorfman       0.66      0.66      0.66        50\n",
            " DarrenSchuettler       0.22      0.26      0.24        50\n",
            "      DavidLawder       0.36      0.20      0.26        50\n",
            "    EdnaFernandes       0.59      0.34      0.43        50\n",
            "      EricAuchard       0.53      0.38      0.44        50\n",
            "   FumikoFujisaki       0.85      1.00      0.92        50\n",
            "   GrahamEarnshaw       0.70      0.88      0.78        50\n",
            " HeatherScoffield       0.32      0.42      0.36        50\n",
            "       JanLopatka       0.55      0.56      0.55        50\n",
            "    JaneMacartney       0.35      0.12      0.18        50\n",
            "     JimGilchrist       0.85      1.00      0.92        50\n",
            "   JoWinterbottom       0.84      0.86      0.85        50\n",
            "         JoeOrtiz       0.45      0.60      0.51        50\n",
            "     JohnMastrini       0.46      0.60      0.52        50\n",
            "     JonathanBirt       0.68      0.76      0.72        50\n",
            "      KarlPenhaul       0.91      1.00      0.95        50\n",
            "        KeithWeir       0.74      0.70      0.72        50\n",
            "   KevinDrawbaugh       0.56      0.46      0.51        50\n",
            "    KevinMorrison       0.48      0.78      0.59        50\n",
            "    KirstinRidley       0.96      0.46      0.62        50\n",
            "KouroshKarimkhany       0.66      0.78      0.72        50\n",
            "        LydiaZajc       0.94      0.60      0.73        50\n",
            "   LynneO'Donnell       0.89      0.78      0.83        50\n",
            "  LynnleyBrowning       0.91      0.96      0.93        50\n",
            "  MarcelMichelson       0.53      0.84      0.65        50\n",
            "     MarkBendeich       0.85      0.82      0.84        50\n",
            "       MartinWolk       0.96      0.54      0.69        50\n",
            "     MatthewBunce       0.98      0.92      0.95        50\n",
            "    MichaelConnor       0.92      0.88      0.90        50\n",
            "       MureDickie       0.40      0.52      0.45        50\n",
            "        NickLouth       0.77      0.94      0.85        50\n",
            "  PatriciaCommins       0.69      0.76      0.72        50\n",
            "    PeterHumphrey       0.44      0.78      0.56        50\n",
            "       PierreTran       0.72      0.26      0.38        50\n",
            "       RobinSidel       0.70      0.86      0.77        50\n",
            "     RogerFillion       0.89      0.80      0.84        50\n",
            "      SamuelPerry       0.41      0.48      0.44        50\n",
            "     SarahDavison       0.58      0.52      0.55        50\n",
            "      ScottHillis       0.29      0.24      0.26        50\n",
            "      SimonCowell       0.60      0.56      0.58        50\n",
            "         TanEeLyn       0.44      0.32      0.37        50\n",
            "   TheresePoletti       0.70      0.64      0.67        50\n",
            "       TimFarrand       0.73      0.76      0.75        50\n",
            "       ToddNissen       0.43      0.66      0.52        50\n",
            "     WilliamKazer       0.37      0.22      0.28        50\n",
            "\n",
            "         accuracy                           0.62      2500\n",
            "        macro avg       0.64      0.62      0.61      2500\n",
            "     weighted avg       0.64      0.62      0.61      2500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# vectorize x_train and x_test from text to matrix\n",
        "vect = TfidfVectorizer(stop_words='english')\n",
        "x_train_vec = vect.fit_transform(X_train)\n",
        "x_test_vec = vect.transform(X_test)\n",
        "\n",
        "# use logistical regression\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train_vec, y_train)\n",
        "\n",
        "# predict and check accuracy\n",
        "pred = model.predict(x_test_vec)\n",
        "rep = classification_report(y_test, pred)"
      ],
      "metadata": {
        "id": "71S6aDElmfr-"
      },
      "id": "71S6aDElmfr-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad17f921-0711-4537-961b-6ff6ed40c017",
      "metadata": {
        "id": "ad17f921-0711-4537-961b-6ff6ed40c017",
        "outputId": "5cc6238c-841f-4f56-b248-7c14fd8ea47a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "../C50train\n",
            "['AaronPressman' 'AlanCrosby' 'AlexanderSmith' 'BenjaminKangLim'\n",
            " 'BernardHickey' 'BradDorfman' 'DarrenSchuettler' 'DavidLawder'\n",
            " 'EdnaFernandes' 'EricAuchard' 'FumikoFujisaki' 'GrahamEarnshaw'\n",
            " 'HeatherScoffield' 'JaneMacartney' 'JanLopatka' 'JimGilchrist' 'JoeOrtiz'\n",
            " 'JohnMastrini' 'JonathanBirt' 'JoWinterbottom' 'KarlPenhaul' 'KeithWeir'\n",
            " 'KevinDrawbaugh' 'KevinMorrison' 'KirstinRidley' 'KouroshKarimkhany'\n",
            " 'LydiaZajc' \"LynneO'Donnell\" 'LynnleyBrowning' 'MarcelMichelson'\n",
            " 'MarkBendeich' 'MartinWolk' 'MatthewBunce' 'MichaelConnor' 'MureDickie'\n",
            " 'NickLouth' 'PatriciaCommins' 'PeterHumphrey' 'PierreTran' 'RobinSidel'\n",
            " 'RogerFillion' 'SamuelPerry' 'SarahDavison' 'ScottHillis' 'SimonCowell'\n",
            " 'TanEeLyn' 'TheresePoletti' 'TimFarrand' 'ToddNissen' 'WilliamKazer']\n",
            "(2500,)\n",
            "(2500,)\n",
            "[50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50\n",
            " 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50\n",
            " 50 50]\n",
            "The Internet may be overflowing with new technology but crime in cyberspace is still of the old-fashioned variety.The National Consumers League said Wednesday that the most popular scam on the Internet was the pyramid scheme, in which early investors in a bogus fund are paid off with deposits of later investors.The league, a non-profit consumer advocacy group, tracks web scams through a site it set up on the world wide web in February called Internet Fraud Watch at http://www.fraud.org.The site, which collects reports directly from consumers, has been widely praised by law enforcement agencies.\"Consumers who suspect a scam on the Internet have critical information,\" said Jodie Bernstein, director of the Federal Trade Commission's Bureau of Consumer Protection. Internet Fraud Watch \"has been a major help to the FTC in identifying particular scams in their infancy.\"In May, for example, the commission used Internet reports to shut down a site run by Fortuna Alliance that had taken in over $6 million, promising investors they could earn $5,000 a month from an initial deposit of $250. Instead, Fortuna kept most of the money, the commission charged.Fraud reports from the league's site, which has been visited over 370,000 times, are forwarded to local, state and federal authorities.The second-most-popular Internet scam, the league said, was the sale of bogus Internet services, such as custom designed web sites or Internet access accounts.In third place were crooks who sell computer equipment, such as memory chips or sound boards, over the net and then deliver significantly lower quality goods or nothing at all, the league said.Other top scams involve business opportunities. Con artists may offer shares in a business or franchise using unreasonable predictions or misrepresentations. One popular scheme promised to let consumers get rich while working at home.The League also announced Tuesday that NationsBank had donated $100,000 to become a sponsor of the Fraud Watch site.\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# get name of directories, authors (these will be the labels)\n",
        "train_sub = [name for name in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, name))]\n",
        "label_lst = np.copy(train_sub)\n",
        "\n",
        "if debug:\n",
        "    print(train_dir)\n",
        "    print(label_lst)\n",
        "\n",
        "# setup the initial empty variables\n",
        "train = []\n",
        "train_v = []\n",
        "label = []\n",
        "\n",
        "# load the input data from C50train directory and process it\n",
        "\n",
        "# format will be something like this\n",
        "# ===================================\n",
        "# | Label         | Train           |\n",
        "# ===================================\n",
        "# | AaronPressman | 2537newsML.txt  |\n",
        "# ===================================\n",
        "# | AaronPressman | 14014newsML.txt |\n",
        "# ===================================\n",
        "# | ...           | ...             |\n",
        "# ===================================\n",
        "# | AlanCrosby    | 10306newsML.txt |\n",
        "# ===================================\n",
        "# | ...           | ...             |\n",
        "\n",
        "\n",
        "auth_idx = 0\n",
        "\n",
        "# go within the author directory to get list of the file names, this will be the training data\n",
        "for i in train_sub:\n",
        "    sub2_dir  = '../C50train/' + i\n",
        "    train_sub2 = [name for name in os.listdir(sub2_dir) if os.path.isfile(os.path.join(sub2_dir, name))]\n",
        "\n",
        "    #if debug:\n",
        "    #    print(sub2_dir)\n",
        "    #    print(train_sub2)\n",
        "\n",
        "    # in each author file, save the author as the label and the text as its training data\n",
        "    for j in train_sub2:\n",
        "        sub3  = '../C50train/' + i + '/' + j\n",
        "\n",
        "        with open(sub3, 'r') as file:\n",
        "            data = file.read()\n",
        "            data_no_nw = data.replace('\\n', '').replace('\\r', '')\n",
        "            train.append(data_no_nw)\n",
        "\n",
        "        # append author index as label\n",
        "        label.append(auth_idx)\n",
        "\n",
        "    # increment author index\n",
        "    auth_idx = auth_idx + 1\n",
        "\n",
        "        #if debug:\n",
        "        #    print(sub3)\n",
        "\n",
        "if debug:\n",
        "    print(np.shape(train))\n",
        "    print(np.shape(label))\n",
        "\n",
        "    # bin count looking at label\n",
        "    unused, idx = np.unique(label, return_counts=True)\n",
        "    #print(unused)\n",
        "    print(idx)\n",
        "\n",
        "    print(train[0])\n",
        "    print(label[0])\n",
        "    #print(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e772bdec-4cc2-4d0b-8edf-0f3d5ce2be18",
      "metadata": {
        "id": "e772bdec-4cc2-4d0b-8edf-0f3d5ce2be18",
        "outputId": "c7e572ed-2a8e-4c97-f1fe-3bf135c088da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.80      0.67         5\n",
            "           1       1.00      1.00      1.00         5\n",
            "           2       0.75      0.50      0.60         6\n",
            "           3       0.40      0.67      0.50         3\n",
            "           4       0.60      0.75      0.67         4\n",
            "           5       1.00      0.71      0.83         7\n",
            "           6       1.00      0.80      0.89         5\n",
            "           7       0.50      0.50      0.50         2\n",
            "           8       0.56      1.00      0.71         5\n",
            "           9       1.00      0.40      0.57         5\n",
            "          10       0.90      1.00      0.95         9\n",
            "          11       0.88      0.88      0.88         8\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       0.70      1.00      0.82         7\n",
            "          14       1.00      0.60      0.75         5\n",
            "          15       1.00      1.00      1.00         6\n",
            "          16       0.60      0.75      0.67         4\n",
            "          17       0.60      1.00      0.75         3\n",
            "          18       1.00      1.00      1.00         2\n",
            "          19       1.00      1.00      1.00         4\n",
            "          20       1.00      1.00      1.00         7\n",
            "          21       1.00      0.33      0.50         6\n",
            "          22       0.75      0.60      0.67         5\n",
            "          23       1.00      0.50      0.67         4\n",
            "          24       0.67      0.67      0.67         6\n",
            "          25       1.00      1.00      1.00         5\n",
            "          26       0.78      1.00      0.88         7\n",
            "          27       1.00      1.00      1.00         4\n",
            "          28       1.00      1.00      1.00         6\n",
            "          29       0.83      1.00      0.91         5\n",
            "          30       0.75      1.00      0.86         3\n",
            "          31       1.00      0.82      0.90        11\n",
            "          32       1.00      1.00      1.00         4\n",
            "          33       1.00      0.86      0.92         7\n",
            "          34       0.00      0.00      0.00         4\n",
            "          35       0.75      0.75      0.75         4\n",
            "          36       0.86      1.00      0.92         6\n",
            "          37       0.20      0.50      0.29         2\n",
            "          38       1.00      0.57      0.73         7\n",
            "          39       1.00      1.00      1.00         3\n",
            "          40       0.80      1.00      0.89         4\n",
            "          41       0.38      1.00      0.55         3\n",
            "          42       1.00      0.67      0.80         3\n",
            "          43       0.00      0.00      0.00         4\n",
            "          44       0.60      0.75      0.67         4\n",
            "          45       1.00      0.33      0.50         6\n",
            "          46       0.75      0.60      0.67         5\n",
            "          47       0.86      1.00      0.92         6\n",
            "          48       0.25      0.50      0.33         2\n",
            "          49       0.60      0.43      0.50         7\n",
            "\n",
            "    accuracy                           0.78       250\n",
            "   macro avg       0.78      0.76      0.74       250\n",
            "weighted avg       0.82      0.78      0.77       250\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# split the test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.1, random_state=1)\n",
        "\n",
        "# vectorize x_train and x_test from text to matrix\n",
        "vect = TfidfVectorizer(stop_words='english')\n",
        "x_train_vec = vect.fit_transform(X_train)\n",
        "x_test_vec = vect.transform(X_test)\n",
        "\n",
        "# use logistical regression\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train_vec, y_train)\n",
        "\n",
        "# predict and check accuracy\n",
        "pred = model.predict(x_test_vec)\n",
        "rep = classification_report(y_test, pred)\n",
        "\n",
        "if debug:\n",
        "    print(rep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28313495-93f3-4639-a7c8-6ae25e2fe00d",
      "metadata": {
        "id": "28313495-93f3-4639-a7c8-6ae25e2fe00d",
        "outputId": "c37aa026-f501-4821-c098-eb0371b1cbee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "../C50test\n",
            "['AaronPressman' 'AlanCrosby' 'AlexanderSmith' 'BenjaminKangLim'\n",
            " 'BernardHickey' 'BradDorfman' 'DarrenSchuettler' 'DavidLawder'\n",
            " 'EdnaFernandes' 'EricAuchard' 'FumikoFujisaki' 'GrahamEarnshaw'\n",
            " 'HeatherScoffield' 'JaneMacartney' 'JanLopatka' 'JimGilchrist' 'JoeOrtiz'\n",
            " 'JohnMastrini' 'JonathanBirt' 'JoWinterbottom' 'KarlPenhaul' 'KeithWeir'\n",
            " 'KevinDrawbaugh' 'KevinMorrison' 'KirstinRidley' 'KouroshKarimkhany'\n",
            " 'LydiaZajc' \"LynneO'Donnell\" 'LynnleyBrowning' 'MarcelMichelson'\n",
            " 'MarkBendeich' 'MartinWolk' 'MatthewBunce' 'MichaelConnor' 'MureDickie'\n",
            " 'NickLouth' 'PatriciaCommins' 'PeterHumphrey' 'PierreTran' 'RobinSidel'\n",
            " 'RogerFillion' 'SamuelPerry' 'SarahDavison' 'ScottHillis' 'SimonCowell'\n",
            " 'TanEeLyn' 'TheresePoletti' 'TimFarrand' 'ToddNissen' 'WilliamKazer']\n",
            "(2500,)\n"
          ]
        }
      ],
      "source": [
        "# Load in C50test located ../C50test/\n",
        "test_dir = '../C50test'\n",
        "# get name of directories, authors (these will be the labels)\n",
        "test_sub = [name for name in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, name))]\n",
        "test_lst = np.copy(train_sub)\n",
        "\n",
        "if debug:\n",
        "    print(test_dir)\n",
        "    print(test_lst)\n",
        "\n",
        "# setup the initial empty variables\n",
        "test       = []\n",
        "test_label = []\n",
        "\n",
        "# load the input data from C50test directory and process it\n",
        "\n",
        "auth_idx = 0\n",
        "\n",
        "# go within the author directory to get list of the file names, this will be the training data\n",
        "for i in train_sub:\n",
        "    sub2_dir  = '../C50test/' + i\n",
        "    test_sub2 = [name for name in os.listdir(sub2_dir) if os.path.isfile(os.path.join(sub2_dir, name))]\n",
        "\n",
        "    #if debug:\n",
        "    #    print(sub2_dir)\n",
        "    #    print(train_sub2)\n",
        "\n",
        "    # in each author file, save the text as its test data\n",
        "    for j in test_sub2:\n",
        "        sub3  = '../C50test/' + i + '/' + j\n",
        "\n",
        "        with open(sub3, 'r') as file:\n",
        "            data = file.read()\n",
        "            data_no_nw = data.replace('\\n', '').replace('\\r', '')\n",
        "            test.append(data_no_nw)\n",
        "\n",
        "        test_label.append(auth_idx)\n",
        "\n",
        "    auth_idx = auth_idx + 1\n",
        "\n",
        "if debug:\n",
        "    print(np.shape(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2afa7db-fa43-4daa-9ae4-715cb3768b7c",
      "metadata": {
        "id": "c2afa7db-fa43-4daa-9ae4-715cb3768b7c",
        "outputId": "71f6413a-482c-4530-9086-1ceef93862c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0  0 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0 44  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 41  0  0\n",
            "  5  0  1  1  1  1 17  1 14 17  1 21 17 17  1 14 14  1 14 14  1  1  1 17\n",
            "  1 17 17  1 17 17 17 17 17 17  1  1  1  1 14  1 14  1  1 17 17 17 17  1\n",
            "  1  1  1  1  2 16  2 16 16 16 16 16 16 16  2 16  2 16 16 16 16 16 16 16\n",
            " 16 16  2 16 16 16 16  2 44  2 44  2 16 16  0  2 16  2 16 16 16 16 16 16\n",
            " 16 18  2  2 16  2 13 37  3 49 11 27 11 49  3 13  3  3 43  3 37 43 13 13\n",
            " 13  3 49 13 13  3 37  3  3 49 49 49 43 43 13 13 34 34 34 34 34 34 34 34\n",
            " 34 13 49 34  3 49 43 43  4  4  4  4  4  4  4  4  4 23  4  5  5 23 23 30\n",
            " 23  4 30 23 30 23 23 23  4  4  4  4  4 23  4 23  4  4 23 23 23 23 23  4\n",
            "  4  4  4 23 23 23 23 23 23 30  5  5  5  5  5  5 41  5  5  5  5  9  5  5\n",
            " 39 39  5 22  5  5  5  5 22  5  5  5  5  9  5  5  5  5  5  5  5  5  5  5\n",
            "  5  5  5  5  5  5 35  5  5 22  5  5 12  6  6  6  6 12  6  6  6 12  6 12\n",
            "  6 12 12 12 12 12 12 12  6 12 12 12 12 12 12 12  6 12 12 12 12  6  6 12\n",
            " 12  6 12 12 12 12 12 12 12 12 12 12 12 12 48  7  7 48 36 36  7  5  5 48\n",
            " 48 48 33 48  7 48 39 48  7 48 41 48 48 48  7 48 48 48 48 48 48 48 48  7\n",
            " 48 48 43 48  7  7  7 48 48 48  5  7  7 48  7  7  8  8 30  8  8  8 39 39\n",
            " 39 39 47 47  8 19 19 19  8  8 48 30  8 18 47 47 48 48  8 19 48 48 48 48\n",
            " 48  8  8  8 18  8  8  8  8  8  8 47 39 39  8  8  8  8 22  9  9  9  9  9\n",
            "  9  9 22  9 46 46  9  9  5 40 46 25 41 41  9  9  9  9  9  9  9  9  9  9\n",
            "  9 41 40 40 40 46  9 35 35 22 35 35 35 35 35 35 35 35 35 41 10 10 10 10\n",
            " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
            " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11\n",
            " 11 49 11 11 11 15 11 11 11 34 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
            " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 13 43 11 11\n",
            " 12 12 12 12 12 12 12 12  6  6 12 12 12 12  6 12 12  6  6  6  6 12  6 12\n",
            " 12  6  6 17 17 17  6 12  6 13  6  6 43 43 43 43 13 43 43 29 17 20  6  6\n",
            " 12  6 11 43  3 43 34 34 43 34 13  3 37 13 49  3 34 11  3 34 43 34  3 43\n",
            "  3 34 34 43 43 34 43 34 34 34 43 13 43 43  3 43 43 43  3 43 43 43 43 43\n",
            " 43 43 43  3 14 14 14 17 14 17 17 17 17 17 17 14  1 17 28 17 28 17 17 17\n",
            " 17 14 17 14 14 28 17 14 17 17 14 14 14 14 28 17 17 17 17 17 17 17 17 17\n",
            " 14 14 14 14 17 14 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
            " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
            " 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16  8 16 16 16 16  2 44 16 16\n",
            " 23 44 44 16 16 16 16 16 16 16 16 16 16 16 16 16  2 16 16  2 16 16 16 16\n",
            " 44 44 44 44 44 16 16 16 16 44 17 17 17 17 17 17 17 17 17 17 17 14 14 17\n",
            " 14 14 14 17 17 17 17  1 17 17 17 14 17 14 17 14 17 28 17 17 17 17 17 17\n",
            " 17 17 17 17 17 17 14 14 17 14 14 14 18 18 18 19 18 18 18 18 18 28 18 18\n",
            " 18 18 18 18 18 18 18 18 18 18 18 18 47 47 18 47 18 44 44 47 47 18 18 18\n",
            "  8 18 18 18 18 47 18 18 18 18  8 18 18 18 19 19 19 19 19 19 19 19 19 19\n",
            " 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19  5 47\n",
            " 19 19 19 19 19 19 19 19 19 19 19 19 19 18 19]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.92      0.88        50\n",
            "           1       0.93      0.50      0.65        50\n",
            "           2       0.65      0.26      0.37        50\n",
            "           3       0.31      0.20      0.24        50\n",
            "           4       0.66      0.46      0.54        50\n",
            "           5       0.63      0.82      0.71        50\n",
            "           6       0.33      0.28      0.30        50\n",
            "           7       0.58      0.28      0.38        50\n",
            "           8       0.82      0.46      0.59        50\n",
            "           9       0.39      0.44      0.42        50\n",
            "          10       0.93      1.00      0.96        50\n",
            "          11       0.75      0.90      0.82        50\n",
            "          12       0.33      0.38      0.35        50\n",
            "          13       0.12      0.06      0.08        50\n",
            "          14       0.47      0.36      0.41        50\n",
            "          15       0.89      1.00      0.94        50\n",
            "          16       0.47      0.72      0.57        50\n",
            "          17       0.42      0.70      0.53        50\n",
            "          18       0.70      0.76      0.73        50\n",
            "          19       0.87      0.94      0.90        50\n",
            "          20       0.94      0.98      0.96        50\n",
            "          21       0.77      0.80      0.78        50\n",
            "          22       0.59      0.76      0.67        50\n",
            "          23       0.48      0.64      0.55        50\n",
            "          24       0.96      0.50      0.66        50\n",
            "          25       0.81      0.70      0.75        50\n",
            "          26       0.97      0.68      0.80        50\n",
            "          27       0.91      0.80      0.85        50\n",
            "          28       0.85      1.00      0.92        50\n",
            "          29       0.67      0.74      0.70        50\n",
            "          30       0.73      0.66      0.69        50\n",
            "          31       0.83      0.50      0.62        50\n",
            "          32       0.96      0.90      0.93        50\n",
            "          33       0.83      0.86      0.84        50\n",
            "          34       0.27      0.44      0.33        50\n",
            "          35       0.69      0.84      0.76        50\n",
            "          36       0.77      0.60      0.67        50\n",
            "          37       0.43      0.82      0.57        50\n",
            "          38       0.81      0.58      0.67        50\n",
            "          39       0.75      0.78      0.76        50\n",
            "          40       0.88      0.74      0.80        50\n",
            "          41       0.54      0.72      0.62        50\n",
            "          42       0.60      0.48      0.53        50\n",
            "          43       0.23      0.32      0.27        50\n",
            "          44       0.65      0.88      0.75        50\n",
            "          45       0.52      0.26      0.35        50\n",
            "          46       0.80      0.80      0.80        50\n",
            "          47       0.67      0.76      0.71        50\n",
            "          48       0.38      0.52      0.44        50\n",
            "          49       0.34      0.24      0.28        50\n",
            "\n",
            "    accuracy                           0.63      2500\n",
            "   macro avg       0.65      0.63      0.63      2500\n",
            "weighted avg       0.65      0.63      0.63      2500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "new_test_vec = vect.transform(test)\n",
        "\n",
        "new_pred = model.predict(new_test_vec)\n",
        "\n",
        "rep = classification_report(test_label, new_pred)\n",
        "\n",
        "if debug:\n",
        "    print(new_pred[0:999])\n",
        "    print(rep)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}