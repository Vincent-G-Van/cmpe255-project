{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project: Authorship Identification\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD,PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup debug for prints troubleshooting\n",
    "# debug = True\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in C50train located ../C50train/\n",
    "train_dir = 'C:/Users/esthe/Downloads/CMPE 255 Project/cmpe255-project/C50train/'\n",
    "# get name of directories, authors (these will be the labels)\n",
    "train_sub = [name for name in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, name))]\n",
    "label_lst = np.copy(train_sub)\n",
    "\n",
    "if debug:\n",
    "    print(train_dir)\n",
    "    print(label_lst)\n",
    "\n",
    "# setup the initial empty variables\n",
    "train = []\n",
    "train_v = []\n",
    "label = []\n",
    "\n",
    "# load the input data from C50train directory and process it\n",
    "auth_idx = 0\n",
    "\n",
    "# go within the author directory to get list of the file names, this will be the training data\n",
    "for i in train_sub:\n",
    "    sub2_dir  = 'C:/Users/esthe/Downloads/CMPE 255 Project/cmpe255-project/C50train/' + i \n",
    "#     '../C50train/'\n",
    "    train_sub2 = [name for name in os.listdir(sub2_dir) if os.path.isfile(os.path.join(sub2_dir, name))]\n",
    "\n",
    "    #if debug:\n",
    "    #    print(sub2_dir)\n",
    "    #    print(train_sub2)\n",
    "        \n",
    "    # in each author file, save the author as the label and the text as its training data\n",
    "    for j in train_sub2:\n",
    "        sub3  = 'C:/Users/esthe/Downloads/CMPE 255 Project/cmpe255-project/C50train/' + i + '/' + j\n",
    "\n",
    "        with open(sub3, 'r') as file:\n",
    "            data = file.read()\n",
    "            data_no_nw = data.replace('\\n', '').replace('\\r', '')\n",
    "            train.append(data_no_nw)\n",
    "\n",
    "        # append author index as label\n",
    "        label.append(auth_idx)\n",
    "\n",
    "    # increment author index\n",
    "    auth_idx = auth_idx + 1\n",
    "        \n",
    "        #if debug:\n",
    "        #    print(sub3)\n",
    "\n",
    "if debug:\n",
    "    print(np.shape(train))\n",
    "    print(np.shape(label))\n",
    "\n",
    "    # bin count looking at label\n",
    "    unused, idx = np.unique(label, return_counts=True)\n",
    "    #print(unused)\n",
    "    print(idx)\n",
    "\n",
    "    print(train[0])\n",
    "    print(label[0])\n",
    "    #print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Vectorize/Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Feature Shape: (2500, 29216)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Convert text to TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "#     max_features=10000,  # Limit to the top 10,000 features for performance\n",
    "    stop_words='english',  # Remove common English stopwords\n",
    "    lowercase=True,  # Convert text to lowercase\n",
    "    )\n",
    "\n",
    "# Transform text data into TF-IDF feature vectors\n",
    "X = tfidf_vectorizer.fit_transform(train)\n",
    "y = np.array(label)\n",
    "\n",
    "print(f\"TF-IDF Feature Shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix as sp_csr_matrix\n",
    "def normalize_csr_matrix(csr_matrix):\n",
    "    norm_data = []\n",
    "    norm_rows = []\n",
    "    norm_cols = []\n",
    "    \n",
    "    for i in range(csr_matrix.shape[0]):\n",
    "        row = csr_matrix[i].toarray().flatten()  # Convert row to a dense array and flatten it\n",
    "        norm = np.linalg.norm(row)  # Compute the L2 norm (Euclidean norm) of the row\n",
    "        \n",
    "        # If the norm is not zero, normalize the row\n",
    "        if norm > 0:\n",
    "            norm_row = row / norm\n",
    "            # Collect non-zero entries\n",
    "            for j in range(len(norm_row)):\n",
    "                if norm_row[j] != 0:\n",
    "                    norm_data.append(norm_row[j])\n",
    "                    norm_rows.append(i)  # Row index\n",
    "                    norm_cols.append(j)  # Column index\n",
    "\n",
    "    # Create a new sparse matrix from the normalized data\n",
    "    normalized_csr_matrix = sp_csr_matrix((norm_data, (norm_rows, norm_cols)), \n",
    "                                           shape=csr_matrix.shape)\n",
    "    return normalized_csr_matrix\n",
    "\n",
    "X = normalize_csr_matrix(X)\n",
    "# y = normalize_csr_matrix(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Shape: (2000, 29216), Test Set Shape: (500, 29216)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train Set Shape: {X_train.shape}, Test Set Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4-5: Dimensionality Reduction + Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Dimensionality Reduction with Truncated SVD\n",
    "svd = TruncatedSVD(n_components=1750, random_state=42) \n",
    "\n",
    "# Step 4: Dimensionality Reduction with PCA\n",
    "# pca = PCA(n_components=1500, random_state=42)  \n",
    "\n",
    "# Normalize the data\n",
    "normalizer = Normalizer(norm='l2',copy=False)\n",
    "\n",
    "# # Scale the data \n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.77         6\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       0.67      0.86      0.75         7\n",
      "           3       0.58      0.64      0.61        11\n",
      "           4       1.00      0.71      0.83        14\n",
      "           5       0.67      0.91      0.77        11\n",
      "           6       0.83      1.00      0.91         5\n",
      "           7       0.86      1.00      0.92         6\n",
      "           8       0.83      0.62      0.71        16\n",
      "           9       0.92      0.86      0.89        14\n",
      "          10       0.91      1.00      0.95        10\n",
      "          11       1.00      1.00      1.00         8\n",
      "          12       0.90      0.82      0.86        11\n",
      "          13       0.58      0.70      0.64        10\n",
      "          14       0.67      0.80      0.73         5\n",
      "          15       0.89      1.00      0.94         8\n",
      "          16       1.00      0.62      0.76        13\n",
      "          17       1.00      0.67      0.80         6\n",
      "          18       0.71      1.00      0.83        10\n",
      "          19       1.00      0.57      0.73         7\n",
      "          20       1.00      1.00      1.00        10\n",
      "          21       1.00      0.94      0.97        17\n",
      "          22       0.88      0.78      0.82         9\n",
      "          23       0.60      1.00      0.75         6\n",
      "          24       0.71      0.83      0.77         6\n",
      "          25       0.81      0.87      0.84        15\n",
      "          26       0.92      0.92      0.92        12\n",
      "          27       1.00      1.00      1.00         9\n",
      "          28       1.00      1.00      1.00        10\n",
      "          29       0.78      1.00      0.88        14\n",
      "          30       0.88      0.64      0.74        11\n",
      "          31       0.75      0.86      0.80         7\n",
      "          32       1.00      1.00      1.00        11\n",
      "          33       0.83      1.00      0.91        10\n",
      "          34       0.62      0.56      0.59         9\n",
      "          35       1.00      0.89      0.94         9\n",
      "          36       0.71      0.56      0.62         9\n",
      "          37       0.69      1.00      0.81        11\n",
      "          38       0.88      0.75      0.81        20\n",
      "          39       1.00      0.71      0.83        14\n",
      "          40       0.86      1.00      0.92        12\n",
      "          41       0.78      0.78      0.78         9\n",
      "          42       0.88      0.88      0.88         8\n",
      "          43       0.43      0.30      0.35        10\n",
      "          44       0.78      1.00      0.88         7\n",
      "          45       1.00      0.45      0.62        11\n",
      "          46       0.90      0.82      0.86        11\n",
      "          47       0.67      1.00      0.80         6\n",
      "          48       1.00      0.71      0.83         7\n",
      "          49       0.47      0.58      0.52        12\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.83      0.83      0.82       500\n",
      "weighted avg       0.84      0.82      0.82       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Adding class weights to handle imbalance\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}  # Regularization strength\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='f1_weighted')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=100, class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
       "                   random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=100, class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
       "                   random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=100, class_weight='balanced', max_iter=1000,\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.77         6\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       0.67      0.86      0.75         7\n",
      "           3       0.58      0.64      0.61        11\n",
      "           4       1.00      0.71      0.83        14\n",
      "           5       0.67      0.91      0.77        11\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.86      1.00      0.92         6\n",
      "           8       0.83      0.62      0.71        16\n",
      "           9       1.00      0.86      0.92        14\n",
      "          10       0.91      1.00      0.95        10\n",
      "          11       1.00      1.00      1.00         8\n",
      "          12       0.90      0.82      0.86        11\n",
      "          13       0.58      0.70      0.64        10\n",
      "          14       0.67      0.80      0.73         5\n",
      "          15       0.89      1.00      0.94         8\n",
      "          16       1.00      0.54      0.70        13\n",
      "          17       1.00      0.67      0.80         6\n",
      "          18       0.75      0.90      0.82        10\n",
      "          19       0.67      0.57      0.62         7\n",
      "          20       1.00      1.00      1.00        10\n",
      "          21       1.00      1.00      1.00        17\n",
      "          22       0.78      0.78      0.78         9\n",
      "          23       0.60      1.00      0.75         6\n",
      "          24       0.71      0.83      0.77         6\n",
      "          25       0.87      0.87      0.87        15\n",
      "          26       0.92      1.00      0.96        12\n",
      "          27       1.00      1.00      1.00         9\n",
      "          28       1.00      1.00      1.00        10\n",
      "          29       0.82      1.00      0.90        14\n",
      "          30       0.88      0.64      0.74        11\n",
      "          31       0.86      0.86      0.86         7\n",
      "          32       1.00      1.00      1.00        11\n",
      "          33       0.83      1.00      0.91        10\n",
      "          34       0.50      0.56      0.53         9\n",
      "          35       1.00      0.89      0.94         9\n",
      "          36       1.00      0.56      0.71         9\n",
      "          37       0.69      1.00      0.81        11\n",
      "          38       0.82      0.70      0.76        20\n",
      "          39       1.00      0.64      0.78        14\n",
      "          40       0.86      1.00      0.92        12\n",
      "          41       0.69      1.00      0.82         9\n",
      "          42       0.88      0.88      0.88         8\n",
      "          43       0.33      0.20      0.25        10\n",
      "          44       0.64      1.00      0.78         7\n",
      "          45       1.00      0.45      0.62        11\n",
      "          46       0.90      0.82      0.86        11\n",
      "          47       0.75      1.00      0.86         6\n",
      "          48       1.00      0.71      0.83         7\n",
      "          49       0.47      0.58      0.52        12\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.83      0.83      0.81       500\n",
      "weighted avg       0.84      0.82      0.81       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Create a Pipeline with Dimensionality Reduction and Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('svd', svd),\n",
    "#     ('pca', pca),\n",
    "    ('normalize', normalizer),\n",
    "    ('classifier', LogisticRegression(C=100, class_weight='balanced', max_iter=1000,random_state=42)),\n",
    "#     ('classifier', LogisticRegression(max_iter=500, random_state=42)),\n",
    "#     ('classifier', RandomForestClassifier(n_estimators=200, random_state=42)),  # Random Forest with class balancing\n",
    "#     ('classifier', SVC(kernel='rbf', class_weight='balanced', random_state=42)),\n",
    "    ])\n",
    "\n",
    "# Train the Model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score: 0.8138\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Calculate F1 Score\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"Weighted F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Explained Variance by SVD: 0.9611\n"
     ]
    }
   ],
   "source": [
    "# Analyze the Dimensionality Reduction\n",
    "explained_variance_svd = svd.explained_variance_.sum()\n",
    "print(f\"Total Explained Variance by SVD: {explained_variance_svd:.4f}\")\n",
    "\n",
    "# explained_variance_pca = pca.explained_variance_.sum()\n",
    "# print(f\"Total Explained Variance by PCA: {explained_variance_pca:.4f}\")\n",
    "\n",
    "# # Optional Visualization of Explained Variance\n",
    "# plt.plot(np.cumsum(svd.explained_variance_))\n",
    "# plt.title('Cumulative Explained Variance by SVD Components')\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Cumulative Explained Variance')\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in C50test located ../C50test/\n",
    "test_dir = 'C:/Users/esthe/Downloads/CMPE 255 Project/cmpe255-project/C50test/'\n",
    "# '../C50test'\n",
    "\n",
    "# get name of directories, authors (these will be the labels)\n",
    "test_sub = [name for name in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, name))]\n",
    "test_lst = np.copy(train_sub)\n",
    "\n",
    "if debug:\n",
    "    print(test_dir)\n",
    "    print(test_lst)\n",
    "\n",
    "# setup the initial empty variables\n",
    "test       = []\n",
    "test_label = []\n",
    "\n",
    "# load the input data from C50test directory and process it\n",
    "\n",
    "auth_idx = 0\n",
    "\n",
    "# go within the author directory to get list of the file names, this will be the training data\n",
    "for i in train_sub:\n",
    "    sub2_dir  = 'C:/Users/esthe/Downloads/CMPE 255 Project/cmpe255-project/C50test/' + i \n",
    "    test_sub2 = [name for name in os.listdir(sub2_dir) if os.path.isfile(os.path.join(sub2_dir, name))]\n",
    "\n",
    "    #if debug:\n",
    "    #    print(sub2_dir)\n",
    "    #    print(train_sub2)\n",
    "        \n",
    "    # in each author file, save the text as its test data\n",
    "    for j in test_sub2:\n",
    "        sub3  = 'C:/Users/esthe/Downloads/CMPE 255 Project/cmpe255-project/C50test/' + i + '/' + j\n",
    "\n",
    "        with open(sub3, 'r') as file:\n",
    "            data = file.read()\n",
    "            data_no_nw = data.replace('\\n', '').replace('\\r', '')\n",
    "            test.append(data_no_nw)\n",
    "        \n",
    "        test_label.append(auth_idx)\n",
    "\n",
    "    auth_idx = auth_idx + 1\n",
    "\n",
    "if debug:\n",
    "    print(np.shape(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Test Feature Shape: (2500, 29216)\n"
     ]
    }
   ],
   "source": [
    "# Transform Test Data into TF-IDF Features\n",
    "X_test_new = tfidf_vectorizer.transform(test)  # Use the trained vectorizer on test data\n",
    "y_test_new = np.array(test_label)\n",
    "\n",
    "print(f\"Transformed Test Feature Shape: {X_test_new.shape}\")\n",
    "# X_test_new = normalize_csr_matrix(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91        50\n",
      "           1       0.83      0.48      0.61        50\n",
      "           2       0.52      0.34      0.41        50\n",
      "           3       0.37      0.22      0.28        50\n",
      "           4       0.80      0.48      0.60        50\n",
      "           5       0.61      0.92      0.74        50\n",
      "           6       0.38      0.28      0.32        50\n",
      "           7       0.68      0.54      0.60        50\n",
      "           8       0.85      0.44      0.58        50\n",
      "           9       0.47      0.52      0.50        50\n",
      "          10       0.98      1.00      0.99        50\n",
      "          11       0.73      0.92      0.81        50\n",
      "          12       0.32      0.38      0.35        50\n",
      "          13       0.16      0.10      0.12        50\n",
      "          14       0.62      0.40      0.49        50\n",
      "          15       0.89      1.00      0.94        50\n",
      "          16       0.63      0.66      0.65        50\n",
      "          17       0.44      0.80      0.57        50\n",
      "          18       0.75      0.80      0.78        50\n",
      "          19       0.90      0.86      0.88        50\n",
      "          20       0.98      1.00      0.99        50\n",
      "          21       0.72      0.84      0.78        50\n",
      "          22       0.69      0.70      0.69        50\n",
      "          23       0.52      0.76      0.62        50\n",
      "          24       0.90      0.54      0.68        50\n",
      "          25       0.73      0.64      0.68        50\n",
      "          26       0.95      0.82      0.88        50\n",
      "          27       0.93      0.80      0.86        50\n",
      "          28       0.92      0.96      0.94        50\n",
      "          29       0.70      0.80      0.75        50\n",
      "          30       0.83      0.70      0.76        50\n",
      "          31       0.73      0.74      0.73        50\n",
      "          32       1.00      0.94      0.97        50\n",
      "          33       0.85      0.88      0.86        50\n",
      "          34       0.23      0.36      0.28        50\n",
      "          35       0.73      0.86      0.79        50\n",
      "          36       0.82      0.62      0.70        50\n",
      "          37       0.48      0.84      0.61        50\n",
      "          38       0.84      0.62      0.71        50\n",
      "          39       0.90      0.72      0.80        50\n",
      "          40       0.97      0.76      0.85        50\n",
      "          41       0.59      0.58      0.59        50\n",
      "          42       0.54      0.56      0.55        50\n",
      "          43       0.15      0.14      0.14        50\n",
      "          44       0.53      0.90      0.67        50\n",
      "          45       0.57      0.34      0.42        50\n",
      "          46       0.75      0.82      0.78        50\n",
      "          47       0.69      0.80      0.74        50\n",
      "          48       0.53      0.46      0.49        50\n",
      "          49       0.23      0.28      0.25        50\n",
      "\n",
      "    accuracy                           0.66      2500\n",
      "   macro avg       0.68      0.66      0.65      2500\n",
      "weighted avg       0.68      0.66      0.65      2500\n",
      "\n",
      "Weighted F1 Score on Test Data: 0.6539\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Predict on Test Data\n",
    "y_pred_new = pipeline.predict(X_test_new)\n",
    "\n",
    "# Step 3: Evaluate Model on Test Data\n",
    "print(\"Classification Report on Test Data:\")\n",
    "print(classification_report(y_test_new, y_pred_new))\n",
    "\n",
    "# Optional: Calculate Weighted F1 Score\n",
    "f1_new = f1_score(y_test_new, y_pred_new, average='macro')\n",
    "print(f\"Weighted F1 Score on Test Data: {f1_new:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD: \n",
    "\n",
    "    accuracy                           0.62      2500\n",
    "\n",
    "Weighted F1 Score on Test Data: \n",
    "\n",
    "\n",
    "PCA:\n",
    "\n",
    "    accuracy                           0.61      2500\n",
    "\n",
    "Weighted F1 Score on Test Data: 0.6059"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of n_components to explore\n",
    "components_range = [0,500,750,1000,1200,1500]\n",
    "explained_variances = []\n",
    "\n",
    "# Fit PCA for each number of components and record the cumulative explained variance\n",
    "for n in components_range:\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X_train.toarray())  # Convert sparse matrix to dense if necessary\n",
    "    explained_variances.append(np.sum(pca.explained_variance_))  # Cumulative explained variance\n",
    "\n",
    "# Plot the explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(components_range, explained_variances, marker='o', color='b', linestyle='-', markersize=3)\n",
    "plt.title('Explained Variance vs. Number of PCA Components')\n",
    "plt.xlabel('Number of Components (n)')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of test sizes to evaluate\n",
    "test_sizes = [0.10,0.15,0.20,0.25,0.30]  # Test sizes from 10% to 50%\n",
    "f1_scores = []\n",
    "\n",
    "# Evaluate the model for each test size\n",
    "for test_size in test_sizes:\n",
    "    # Split the data\n",
    "    X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(X_train_split, y_train_split)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    y_pred_split = pipeline.predict(X_test_split)\n",
    "    f1 = f1_score(y_test_split, y_pred_split, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Test Size: {test_size:.2f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Plot Test Size vs. F1-Score\n",
    "plt.plot(test_sizes, f1_scores, marker='o', linestyle='-', color='b')\n",
    "plt.title(\"Test Size vs. Weighted F1-Score\")\n",
    "plt.xlabel(\"Test Size\")\n",
    "plt.ylabel(\"Weighted F1-Score\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "all_text = \" \".join(train)\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"Most Frequent Words\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_embedded = tsne.fit_transform(X[:1000].toarray())  # Use a subset for efficiency\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=label[:1000], cmap='viridis', s=5)\n",
    "plt.colorbar()\n",
    "plt.title(\"t-SNE Visualization of Feature Space\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# highlight which classes are misclassified\n",
    "cm = confusion_matrix(y_test_new, y_pred_new)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=False,, fmt='d' cmap='Blues', xticklabels=label_lst, yticklabels=label_lst)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "report = classification_report(y_test_new, y_pred_new, output_dict=True)\n",
    "f1_scores = [report[str(i)]['f1-score'] for i in range(len(label_lst))]\n",
    "plt.bar(label_lst, f1_scores)\n",
    "plt.title(\"F1 Score per Class\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
