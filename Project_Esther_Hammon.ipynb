{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Project: Authorship Identification\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD,PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup debug for prints troubleshooting\n",
    "# debug = True\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in C50train located ../C50train/\n",
    "train_dir = '../C50train'\n",
    "# get name of directories, authors (these will be the labels)\n",
    "train_sub = [name for name in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, name))]\n",
    "label_lst = np.copy(train_sub)\n",
    "\n",
    "if debug:\n",
    "    print(train_dir)\n",
    "    print(label_lst)\n",
    "\n",
    "# setup the initial empty variables\n",
    "train = []\n",
    "train_v = []\n",
    "label = []\n",
    "\n",
    "# load the input data from C50train directory and process it\n",
    "auth_idx = 0\n",
    "\n",
    "# go within the author directory to get list of the file names, this will be the training data\n",
    "for i in train_sub:\n",
    "    sub2_dir  = '../C50train/' + i \n",
    "    train_sub2 = [name for name in os.listdir(sub2_dir) if os.path.isfile(os.path.join(sub2_dir, name))]\n",
    "\n",
    "    #if debug:\n",
    "    #    print(sub2_dir)\n",
    "    #    print(train_sub2)\n",
    "        \n",
    "    # in each author file, save the author as the label and the text as its training data\n",
    "    for j in train_sub2:\n",
    "        sub3  = '../C50train/' + i + '/' + j\n",
    "\n",
    "        with open(sub3, 'r') as file:\n",
    "            data = file.read()\n",
    "            data_no_nw = data.replace('\\n', '').replace('\\r', '')\n",
    "            train.append(data_no_nw)\n",
    "\n",
    "        # append author index as label\n",
    "        label.append(auth_idx)\n",
    "\n",
    "    # increment author index\n",
    "    auth_idx = auth_idx + 1\n",
    "        \n",
    "        #if debug:\n",
    "        #    print(sub3)\n",
    "\n",
    "if debug:\n",
    "    print(np.shape(train))\n",
    "    print(np.shape(label))\n",
    "\n",
    "    # bin count looking at label\n",
    "    unused, idx = np.unique(label, return_counts=True)\n",
    "    #print(unused)\n",
    "    print(idx)\n",
    "\n",
    "    print(train[0])\n",
    "    print(label[0])\n",
    "    #print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Feature Shape: (2500, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Convert text to TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,  # Limit to the top 10,000 features for performance\n",
    "    stop_words='english',  # Remove common English stopwords\n",
    "    lowercase=True,  # Convert text to lowercase\n",
    "    )\n",
    "\n",
    "# Transform text data into TF-IDF feature vectors\n",
    "X = tfidf_vectorizer.fit_transform(train)\n",
    "y = np.array(label)\n",
    "\n",
    "print(f\"TF-IDF Feature Shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Shape: (2125, 10000), Test Set Shape: (375, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)\n",
    "\n",
    "print(f\"Train Set Shape: {X_train.shape}, Test Set Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4-5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Dimensionality Reduction with Truncated SVD\n",
    "svd = TruncatedSVD(n_components=2000, random_state=42) \n",
    "\n",
    "# Step 4: Dimensionality Reduction with PCA\n",
    "# pca = PCA(n_components=2000, random_state=42)  \n",
    "\n",
    "# Normalize the data\n",
    "normalizer = Normalizer(copy=False)\n",
    "\n",
    "# # Scale the data \n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.82         8\n",
      "           1       1.00      0.88      0.93         8\n",
      "           2       0.73      1.00      0.84         8\n",
      "           3       0.80      0.57      0.67         7\n",
      "           4       0.71      0.71      0.71         7\n",
      "           5       0.67      0.50      0.57         8\n",
      "           6       1.00      1.00      1.00         7\n",
      "           7       0.80      1.00      0.89         8\n",
      "           8       0.86      0.86      0.86         7\n",
      "           9       0.64      1.00      0.78         7\n",
      "          10       0.89      1.00      0.94         8\n",
      "          11       0.78      0.88      0.82         8\n",
      "          12       1.00      0.86      0.92         7\n",
      "          13       0.55      0.86      0.67         7\n",
      "          14       0.67      0.75      0.71         8\n",
      "          15       1.00      1.00      1.00         7\n",
      "          16       1.00      0.71      0.83         7\n",
      "          17       1.00      0.71      0.83         7\n",
      "          18       1.00      0.75      0.86         8\n",
      "          19       0.67      0.86      0.75         7\n",
      "          20       1.00      1.00      1.00         8\n",
      "          21       0.71      0.62      0.67         8\n",
      "          22       0.83      0.62      0.71         8\n",
      "          23       0.75      0.75      0.75         8\n",
      "          24       0.33      0.29      0.31         7\n",
      "          25       1.00      0.86      0.92         7\n",
      "          26       1.00      1.00      1.00         7\n",
      "          27       1.00      1.00      1.00         8\n",
      "          28       0.80      1.00      0.89         8\n",
      "          29       0.73      1.00      0.84         8\n",
      "          30       1.00      0.86      0.92         7\n",
      "          31       1.00      1.00      1.00         7\n",
      "          32       1.00      1.00      1.00         7\n",
      "          33       0.88      0.88      0.88         8\n",
      "          34       0.56      0.71      0.62         7\n",
      "          35       0.89      1.00      0.94         8\n",
      "          36       1.00      0.75      0.86         8\n",
      "          37       0.54      1.00      0.70         7\n",
      "          38       1.00      0.75      0.86         8\n",
      "          39       0.88      1.00      0.93         7\n",
      "          40       0.89      1.00      0.94         8\n",
      "          41       1.00      0.86      0.92         7\n",
      "          42       1.00      0.75      0.86         8\n",
      "          43       0.00      0.00      0.00         8\n",
      "          44       0.83      0.62      0.71         8\n",
      "          45       0.67      0.29      0.40         7\n",
      "          46       1.00      0.86      0.92         7\n",
      "          47       0.88      1.00      0.93         7\n",
      "          48       0.56      0.71      0.62         7\n",
      "          49       0.50      0.62      0.56         8\n",
      "\n",
      "    accuracy                           0.81       375\n",
      "   macro avg       0.81      0.81      0.80       375\n",
      "weighted avg       0.81      0.81      0.80       375\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esthe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\esthe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\esthe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Create a Pipeline with Dimensionality Reduction and Classifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('svd', svd),\n",
    "#     ('pca', pca),\n",
    "    ('normalize', normalizer),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42)),\n",
    "#     ('classifier', RandomForestClassifier(n_estimators=200, random_state=42)),  # Random Forest with class balancing\n",
    "#     ('classifier', SVC(kernel='rbf', class_weight='balanced', random_state=42)),\n",
    "    ])\n",
    "\n",
    "# Train the Model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score: 0.8012\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Calculate F1 Score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Weighted F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Explained Variance by SVD: 0.9620\n"
     ]
    }
   ],
   "source": [
    "# Analyze the Dimensionality Reduction\n",
    "explained_variance_svd = svd.explained_variance_.sum()\n",
    "print(f\"Total Explained Variance by SVD: {explained_variance_svd:.4f}\")\n",
    "\n",
    "# explained_variance_pca = pca.explained_variance_.sum()\n",
    "# print(f\"Total Explained Variance by PCA: {explained_variance_pca:.4f}\")\n",
    "\n",
    "# # Optional Visualization of Explained Variance\n",
    "# plt.plot(np.cumsum(svd.explained_variance_))\n",
    "# plt.title('Cumulative Explained Variance by SVD Components')\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.ylabel('Cumulative Explained Variance')\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in C50test located ../C50test/\n",
    "test_dir = '../C50test'\n",
    "# get name of directories, authors (these will be the labels)\n",
    "test_sub = [name for name in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, name))]\n",
    "test_lst = np.copy(train_sub)\n",
    "\n",
    "if debug:\n",
    "    print(test_dir)\n",
    "    print(test_lst)\n",
    "\n",
    "# setup the initial empty variables\n",
    "test       = []\n",
    "test_label = []\n",
    "\n",
    "# load the input data from C50test directory and process it\n",
    "\n",
    "auth_idx = 0\n",
    "\n",
    "# go within the author directory to get list of the file names, this will be the training data\n",
    "for i in train_sub:\n",
    "    sub2_dir  = '../C50test/' + i \n",
    "    test_sub2 = [name for name in os.listdir(sub2_dir) if os.path.isfile(os.path.join(sub2_dir, name))]\n",
    "\n",
    "    #if debug:\n",
    "    #    print(sub2_dir)\n",
    "    #    print(train_sub2)\n",
    "        \n",
    "    # in each author file, save the text as its test data\n",
    "    for j in test_sub2:\n",
    "        sub3  = '../C50test/' + i + '/' + j\n",
    "\n",
    "        with open(sub3, 'r') as file:\n",
    "            data = file.read()\n",
    "            data_no_nw = data.replace('\\n', '').replace('\\r', '')\n",
    "            test.append(data_no_nw)\n",
    "        \n",
    "        test_label.append(auth_idx)\n",
    "\n",
    "    auth_idx = auth_idx + 1\n",
    "\n",
    "if debug:\n",
    "    print(np.shape(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Test Feature Shape: (2500, 10000)\n",
      "Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87        50\n",
      "           1       0.85      0.46      0.60        50\n",
      "           2       0.57      0.26      0.36        50\n",
      "           3       0.32      0.24      0.27        50\n",
      "           4       0.70      0.60      0.65        50\n",
      "           5       0.59      0.86      0.70        50\n",
      "           6       0.36      0.28      0.31        50\n",
      "           7       0.56      0.28      0.37        50\n",
      "           8       0.88      0.42      0.57        50\n",
      "           9       0.40      0.44      0.42        50\n",
      "          10       0.91      1.00      0.95        50\n",
      "          11       0.70      0.92      0.79        50\n",
      "          12       0.32      0.38      0.35        50\n",
      "          13       0.22      0.16      0.18        50\n",
      "          14       0.44      0.36      0.40        50\n",
      "          15       0.89      1.00      0.94        50\n",
      "          16       0.49      0.72      0.59        50\n",
      "          17       0.40      0.62      0.48        50\n",
      "          18       0.79      0.74      0.76        50\n",
      "          19       0.83      0.86      0.84        50\n",
      "          20       0.96      1.00      0.98        50\n",
      "          21       0.72      0.82      0.77        50\n",
      "          22       0.69      0.72      0.71        50\n",
      "          23       0.54      0.62      0.58        50\n",
      "          24       0.93      0.54      0.68        50\n",
      "          25       0.79      0.68      0.73        50\n",
      "          26       0.93      0.80      0.86        50\n",
      "          27       0.89      0.80      0.84        50\n",
      "          28       0.79      1.00      0.88        50\n",
      "          29       0.67      0.72      0.69        50\n",
      "          30       0.73      0.60      0.66        50\n",
      "          31       0.74      0.74      0.74        50\n",
      "          32       0.98      0.90      0.94        50\n",
      "          33       0.88      0.86      0.87        50\n",
      "          34       0.16      0.24      0.20        50\n",
      "          35       0.68      0.86      0.76        50\n",
      "          36       0.80      0.56      0.66        50\n",
      "          37       0.45      0.82      0.58        50\n",
      "          38       0.79      0.62      0.70        50\n",
      "          39       0.80      0.74      0.77        50\n",
      "          40       0.90      0.74      0.81        50\n",
      "          41       0.67      0.66      0.67        50\n",
      "          42       0.67      0.40      0.50        50\n",
      "          43       0.15      0.10      0.12        50\n",
      "          44       0.66      0.78      0.72        50\n",
      "          45       0.47      0.38      0.42        50\n",
      "          46       0.71      0.78      0.74        50\n",
      "          47       0.53      0.78      0.63        50\n",
      "          48       0.40      0.54      0.46        50\n",
      "          49       0.25      0.26      0.25        50\n",
      "\n",
      "    accuracy                           0.63      2500\n",
      "   macro avg       0.65      0.63      0.63      2500\n",
      "weighted avg       0.65      0.63      0.63      2500\n",
      "\n",
      "Weighted F1 Score on Test Data: 0.6264\n"
     ]
    }
   ],
   "source": [
    "# Transform Test Data into TF-IDF Features\n",
    "X_test_new = tfidf_vectorizer.transform(test)  # Use the trained vectorizer on test data\n",
    "y_test_new = np.array(test_label)\n",
    "\n",
    "print(f\"Transformed Test Feature Shape: {X_test_new.shape}\")\n",
    "\n",
    "# Step 2: Predict on Test Data\n",
    "y_pred_new = pipeline.predict(X_test_new)\n",
    "\n",
    "# Step 3: Evaluate Model on Test Data\n",
    "print(\"Classification Report on Test Data:\")\n",
    "print(classification_report(y_test_new, y_pred_new))\n",
    "\n",
    "# Optional: Calculate Weighted F1 Score\n",
    "f1_new = f1_score(y_test_new, y_pred_new, average='weighted')\n",
    "print(f\"Weighted F1 Score on Test Data: {f1_new:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of n_components to explore\n",
    "components_range = range(0,1500,100)  # From 1 to 35 components (you can increase this range if needed)\n",
    "explained_variances = []\n",
    "\n",
    "# Get the number of features (dimensions) in your dataset\n",
    "# n_features = X_train.shape[1]\n",
    "\n",
    "# Ensure that the components do not exceed the number of features\n",
    "# components_range = [n for n in components_range if n <= n_features]\n",
    "\n",
    "# Fit PCA for each number of components and record the cumulative explained variance\n",
    "for n in components_range:\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X_train.toarray())  # Convert sparse matrix to dense if necessary\n",
    "    explained_variances.append(np.sum(pca.explained_variance_))  # Cumulative explained variance\n",
    "\n",
    "# Plot the explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(components_range, explained_variances, marker='o', color='b', linestyle='-', markersize=3)\n",
    "plt.title('Explained Variance vs. Number of PCA Components')\n",
    "plt.xlabel('Number of Components (n)')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of test sizes to evaluate\n",
    "test_sizes = np.linspace(0.1, 0.31, 10)  # Test sizes from 10% to 50%\n",
    "f1_scores = []\n",
    "\n",
    "# Evaluate the model for each test size\n",
    "for test_size in test_sizes:\n",
    "    # Split the data\n",
    "    X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(X_train_split, y_train_split)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    y_pred_split = pipeline.predict(X_test_split)\n",
    "    f1 = f1_score(y_test_split, y_pred_split, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Test Size: {test_size:.2f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Plot Test Size vs. F1-Score\n",
    "plt.plot(test_sizes, f1_scores, marker='o', linestyle='-', color='b')\n",
    "plt.title(\"Test Size vs. Weighted F1-Score\")\n",
    "plt.xlabel(\"Test Size\")\n",
    "plt.ylabel(\"Weighted F1-Score\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "all_text = \" \".join(train)\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"Most Frequent Words\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_embedded = tsne.fit_transform(X[:1000].toarray())  # Use a subset for efficiency\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=label[:1000], cmap='viridis', s=5)\n",
    "plt.colorbar()\n",
    "plt.title(\"t-SNE Visualization of Feature Space\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# highlight which classes are misclassified\n",
    "cm = confusion_matrix(y_test_new, y_pred_new)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=False,, fmt='d' cmap='Blues', xticklabels=label_lst, yticklabels=label_lst)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "report = classification_report(y_test_new, y_pred_new, output_dict=True)\n",
    "f1_scores = [report[str(i)]['f1-score'] for i in range(len(label_lst))]\n",
    "plt.bar(label_lst, f1_scores)\n",
    "plt.title(\"F1 Score per Class\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
